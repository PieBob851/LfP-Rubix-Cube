{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "!git clone https://github.com/PieBob851/LfP-Rubix-Cube.git\n",
        "%cd LfP-Rubix-Cube"
      ],
      "metadata": {
        "id": "Wcdoe1095pLo",
        "outputId": "34183cfb-8c6e-483d-a4dc-a6b2cdd4ee09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "Cloning into 'LfP-Rubix-Cube'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 41 (delta 16), reused 28 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (41/41), 25.55 KiB | 5.11 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "/LfP-Rubix-Cube\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Utils\n"
      ],
      "metadata": {
        "id": "5kZB5Lcq9uDc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3Eu_3Jqu7n",
        "outputId": "7b607e49-aa62-42a0-d87c-08540b2b6866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from model.encoder import Encoder\n",
        "from model.planner import Planner\n",
        "from model.actor import Actor\n",
        "import torch\n",
        "from torch import nn, zeros\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from collections import deque\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install magiccube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfQFoZbGwbFH",
        "outputId": "9eb19bdf-45a6-4347-8411-930345d34427"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting magiccube\n",
            "  Downloading magiccube-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from magiccube) (2.0.2)\n",
            "Downloading magiccube-1.0.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: magiccube\n",
            "Successfully installed magiccube-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import magiccube\n",
        "import copy\n",
        "from magiccube.cube_base import Color, Face\n",
        "from magiccube.cube_move import CubeMove\n",
        "from magiccube.solver.basic.basic_solver import BasicSolver\n",
        "\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "def get_face_state(cube, face):\n",
        "    array_values = np.array([[color.value for color in row] for row in cube.get_face(face)])\n",
        "    tensor = torch.tensor(array_values.flatten(), dtype=torch.int64)\n",
        "    return torch.nn.functional.one_hot(tensor, num_classes=6).flatten()\n",
        "\n",
        "#state space\n",
        "def get_cube_state(cube):\n",
        "    return torch.stack([get_face_state(cube, Face.L), get_face_state(cube, Face.R), get_face_state(cube, Face.D), get_face_state(cube, Face.U), get_face_state(cube, Face.B), get_face_state(cube, Face.F)], dim=0)\n",
        "\n",
        "def batch_cube_state(cube_list):\n",
        "    current_states = []\n",
        "\n",
        "    for cube in cube_list:\n",
        "      current_states.append(get_cube_state(cube))\n",
        "\n",
        "    current_states = torch.stack(current_states)\n",
        "\n",
        "    return current_states.view(current_states.size(0), -1)\n",
        "\n",
        "def batch_apply_action(cube_list, action_list):\n",
        "  for i in range(len(cube_list)):\n",
        "    cube_list[i]._rotate_once(action_list[i])\n",
        "\n",
        "  return cube_list\n",
        "\n",
        "#action space\n",
        "movements = [\"L\", \"L'\", \"L2\", \"R\", \"R'\", \"R2\", \"D\", \"D'\", \"D2\", \"U\", \"U'\", \"U2\", \"B\", \"B'\", \"B2\", \"F\", \"F'\", \"F2\"]\n",
        "reversals = [\"L'\", \"L\", \"L2\", \"R'\", \"R\", \"R2\", \"D'\", \"D\", \"D2\", \"U'\", \"U\", \"U2\", \"B'\", \"B\", \"B2\", \"F'\", \"F\", \"F2\"]\n",
        "reverse_index = {0: 1, 1: 0, 2: 2, 3: 4, 4: 3, 5: 5, 6: 7, 7: 6, 8: 8, 9: 10, 10: 9, 11: 11, 12: 13, 13: 12, 14: 14, 15: 16, 16:15, 17:17}\n",
        "reversals = [CubeMove.create(move_str) for move_str in reversals]\n",
        "movements = [CubeMove.create(move_str) for move_str in movements]\n",
        "\n",
        "# cube._rotate_once(movements[8])\n",
        "# solver = BasicSolver(cube)\n",
        "# cube_copy = copy.deepcopy(cube)\n",
        "# solver.solve()"
      ],
      "metadata": {
        "id": "BzsAMibJsBvI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection\n",
        "\n",
        "Different ways to collect data (only one should be used)"
      ],
      "metadata": {
        "id": "l0gooVAu97L4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random move selection - at every timestep, a random move is chosen"
      ],
      "metadata": {
        "id": "a317An1e-8Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random move at every step for dataset creation\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100000\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "for i in range(num_samples):\n",
        "  if i % 10000 == 0:\n",
        "    print(f\"Sample: {i}\")\n",
        "  state = get_cube_state(cube).flatten()\n",
        "  data_raw[i, :state_dim] = state\n",
        "\n",
        "  action = random.choice(range(action_dim))\n",
        "  data_raw[i, state_dim + action] = 1\n",
        "\n",
        "  cube._rotate_once(movements[action])"
      ],
      "metadata": {
        "id": "raWpW0b_vkBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random move selection with reversing - starts with a solved cube, then advances move_depth steps forward with random move selection. After this, it reverses those moves (so the cube is once again solved)."
      ],
      "metadata": {
        "id": "U2ZakNFh_DTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# forward set number of moves, before reversing\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 1000000\n",
        "move_depth = 16  # Number of forward moves before reversing\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3, \"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "i = 0\n",
        "while i < num_samples:\n",
        "  forward_actions = []\n",
        "  for _ in range(move_depth):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    action = random.choice(range(action_dim))\n",
        "    data_raw[i, state_dim + action] = 1\n",
        "    cube._rotate_once(movements[action])\n",
        "    forward_actions.append(action)\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break\n",
        "\n",
        "  for action in reversed(forward_actions):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    reverse_action = reverse_index[action]\n",
        "    data_raw[i, state_dim + reverse_action] = 1\n",
        "    cube._rotate_once(movements[reverse_action])\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj43AWNf5Qx7",
        "outputId": "0feb0a63-4137-4619-e4c3-b64a6da7f4d5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n",
            "Sample: 10000\n",
            "Sample: 20000\n",
            "Sample: 30000\n",
            "Sample: 40000\n",
            "Sample: 50000\n",
            "Sample: 60000\n",
            "Sample: 70000\n",
            "Sample: 80000\n",
            "Sample: 90000\n",
            "Sample: 100000\n",
            "Sample: 110000\n",
            "Sample: 120000\n",
            "Sample: 130000\n",
            "Sample: 140000\n",
            "Sample: 150000\n",
            "Sample: 160000\n",
            "Sample: 170000\n",
            "Sample: 180000\n",
            "Sample: 190000\n",
            "Sample: 200000\n",
            "Sample: 210000\n",
            "Sample: 220000\n",
            "Sample: 230000\n",
            "Sample: 240000\n",
            "Sample: 250000\n",
            "Sample: 260000\n",
            "Sample: 270000\n",
            "Sample: 280000\n",
            "Sample: 290000\n",
            "Sample: 300000\n",
            "Sample: 310000\n",
            "Sample: 320000\n",
            "Sample: 330000\n",
            "Sample: 340000\n",
            "Sample: 350000\n",
            "Sample: 360000\n",
            "Sample: 370000\n",
            "Sample: 380000\n",
            "Sample: 390000\n",
            "Sample: 400000\n",
            "Sample: 410000\n",
            "Sample: 420000\n",
            "Sample: 430000\n",
            "Sample: 440000\n",
            "Sample: 450000\n",
            "Sample: 460000\n",
            "Sample: 470000\n",
            "Sample: 480000\n",
            "Sample: 490000\n",
            "Sample: 500000\n",
            "Sample: 510000\n",
            "Sample: 520000\n",
            "Sample: 530000\n",
            "Sample: 540000\n",
            "Sample: 550000\n",
            "Sample: 560000\n",
            "Sample: 570000\n",
            "Sample: 580000\n",
            "Sample: 590000\n",
            "Sample: 600000\n",
            "Sample: 610000\n",
            "Sample: 620000\n",
            "Sample: 630000\n",
            "Sample: 640000\n",
            "Sample: 650000\n",
            "Sample: 660000\n",
            "Sample: 670000\n",
            "Sample: 680000\n",
            "Sample: 690000\n",
            "Sample: 700000\n",
            "Sample: 710000\n",
            "Sample: 720000\n",
            "Sample: 730000\n",
            "Sample: 740000\n",
            "Sample: 750000\n",
            "Sample: 760000\n",
            "Sample: 770000\n",
            "Sample: 780000\n",
            "Sample: 790000\n",
            "Sample: 800000\n",
            "Sample: 810000\n",
            "Sample: 820000\n",
            "Sample: 830000\n",
            "Sample: 840000\n",
            "Sample: 850000\n",
            "Sample: 860000\n",
            "Sample: 870000\n",
            "Sample: 880000\n",
            "Sample: 890000\n",
            "Sample: 900000\n",
            "Sample: 910000\n",
            "Sample: 920000\n",
            "Sample: 930000\n",
            "Sample: 940000\n",
            "Sample: 950000\n",
            "Sample: 960000\n",
            "Sample: 970000\n",
            "Sample: 980000\n",
            "Sample: 990000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting Data\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, data):\n",
        "        self.data_list = data\n",
        "\n",
        "    def sample_batch(self, batch_size, plan_len):\n",
        "        start_indices = np.random.randint(0, len(self.data_list) // (plan_len * 2) - 1, size=batch_size)[:, np.newaxis]\n",
        "        start_indices = start_indices * (plan_len * 2) + plan_len\n",
        "        indices = start_indices + np.arange(plan_len + 1)[np.newaxis, :]\n",
        "\n",
        "        sample = self.data_list[indices]\n",
        "        return sample\n",
        "\n",
        "data = Dataset(data_raw)"
      ],
      "metadata": {
        "id": "pdcQeEuiJld9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 128\n",
        "\n",
        "encoder = Encoder(state_dim + action_dim, layer_size=256, latent_dim=latent_dim).to(device)\n",
        "planner = Planner(state_dim, state_dim, layer_size=1024, latent_dim=latent_dim).to(device)\n",
        "actor = Actor(state_dim, action_dim, state_dim, layer_size=1024, latent_dim=latent_dim).to(device)\n",
        "\n",
        "encoder_optimizer = Adam(encoder.parameters(), lr=1e-4)\n",
        "planner_optimizer = Adam(planner.parameters(), lr=1e-4)\n",
        "actor_optimizer = Adam(actor.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "dnqS0mJkMbHd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing\n"
      ],
      "metadata": {
        "id": "Mgt8MyeA-ElT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.distributions as dist\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_sample(batch_size, beta, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer, data, plan_len):\n",
        "    sample = data.sample_batch(batch_size, plan_len).to(device)\n",
        "    losses = []\n",
        "    for i in range(plan_len):\n",
        "        current_state = sample[:, i, :-18]\n",
        "        current_action = sample[:, i, -18:]\n",
        "        goal_state = sample[:, -1, :-18]\n",
        "        goal_action = sample[:, -1, -18:]\n",
        "\n",
        "        z, mu_phi, sigma_phi = encoder.forward(sample)\n",
        "        mu_psi, sigma_psi = planner.forward(current_state, goal_state)\n",
        "\n",
        "        phi_gaussian = dist.Normal(mu_phi, sigma_phi)\n",
        "\n",
        "        psi_gaussian = dist.Normal(mu_psi, sigma_psi)\n",
        "\n",
        "        KL_loss = torch.sum(dist.kl.kl_divergence(phi_gaussian, psi_gaussian))\n",
        "\n",
        "        policy_action, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "        action_loss = F.cross_entropy(policy_action.squeeze(1), current_action)\n",
        "\n",
        "        loss = beta * KL_loss + action_loss\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        planner_optimizer.zero_grad()\n",
        "        actor_optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        planner_optimizer.step()\n",
        "        actor_optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    return sum(losses) / len(losses)"
      ],
      "metadata": {
        "id": "V2A3_IwZB1js"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in range(50000 // move_depth):\n",
        "    loss = train_sample(32, .9, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer, data, move_depth)\n",
        "    if batch % 100 == 0:\n",
        "        print(f\"Batch: {batch}, Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRQTwsBKUjee",
        "outputId": "f2c97ef1-afec-4123-c2f3-51e50829f099"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0, Loss: 2.240416720509529\n",
            "Batch: 100, Loss: 2.1591588873416185\n",
            "Batch: 200, Loss: 2.0319291735067964\n",
            "Batch: 300, Loss: 2.112350581213832\n",
            "Batch: 400, Loss: 2.0157643388956785\n",
            "Batch: 500, Loss: 1.9694203585386276\n",
            "Batch: 600, Loss: 1.9207060476765037\n",
            "Batch: 700, Loss: 1.9307263931259513\n",
            "Batch: 800, Loss: 1.9795893393456936\n",
            "Batch: 900, Loss: 1.9571971306577325\n",
            "Batch: 1000, Loss: 1.8952850503847003\n",
            "Batch: 1100, Loss: 1.8997483532875776\n",
            "Batch: 1200, Loss: 1.8401312679052353\n",
            "Batch: 1300, Loss: 1.779211115092039\n",
            "Batch: 1400, Loss: 1.8657003976404667\n",
            "Batch: 1500, Loss: 1.7245650589466095\n",
            "Batch: 1600, Loss: 1.770142295397818\n",
            "Batch: 1700, Loss: 1.7129919305443764\n",
            "Batch: 1800, Loss: 1.7613434782251716\n",
            "Batch: 1900, Loss: 1.5927450777962804\n",
            "Batch: 2000, Loss: 1.6710727149620652\n",
            "Batch: 2100, Loss: 1.6324873818084598\n",
            "Batch: 2200, Loss: 1.5948121650144458\n",
            "Batch: 2300, Loss: 1.6703677996993065\n",
            "Batch: 2400, Loss: 1.7157585080713034\n",
            "Batch: 2500, Loss: 1.5082753850147128\n",
            "Batch: 2600, Loss: 1.496636332012713\n",
            "Batch: 2700, Loss: 1.4569468218833208\n",
            "Batch: 2800, Loss: 1.364949026145041\n",
            "Batch: 2900, Loss: 1.5753872161731124\n",
            "Batch: 3000, Loss: 1.4237868012860417\n",
            "Batch: 3100, Loss: 1.529769029468298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scramble_n(cube, n):\n",
        "    for _ in range(n):\n",
        "        action = random.choice(movements)\n",
        "        cube._rotate_once(action)\n",
        "\n",
        "def attempt_solve(scramble_moves, max_moves):\n",
        "    cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "    goal_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "    scramble_n(cube, scramble_moves)\n",
        "    with torch.no_grad():\n",
        "      current_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "\n",
        "      for t in range(max_moves):\n",
        "        if t % 16 == 0:\n",
        "            mu_psi, sigma_psi = planner.forward(current_state.float(), goal_state.float())\n",
        "        z = mu_psi + sigma_psi * torch.randn_like(sigma_psi)\n",
        "\n",
        "        actor_dist, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "        action_index = torch.argmax(actor_dist, -1)\n",
        "\n",
        "        cube._rotate_once(movements[action_index])\n",
        "        current_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "        if cube.is_done():\n",
        "            return t + 1\n",
        "    return -1\n",
        "\n",
        "\n",
        "def test_batch(batch_size):\n",
        "\n",
        "    cubes = []\n",
        "    histories = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "      history = cube.scramble(1)\n",
        "\n",
        "      cubes.append(cube)\n",
        "      histories.append(history)\n",
        "\n",
        "    return cubes, histories\n",
        "\n",
        "def test_sample(batch_size, encoder, actor, planner):\n",
        "\n",
        "    goal_cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "    goal_state = get_cube_state(goal_cube)\n",
        "    goal_state = goal_state.unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n",
        "    goal_state = goal_state.view(goal_state.size(0), -1)\n",
        "\n",
        "    cubes, histories = test_batch(batch_size)\n",
        "\n",
        "    solved = [False] * batch_size\n",
        "    steps_taken = [0] * batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "      current_state = batch_cube_state(cubes).to(device)\n",
        "\n",
        "      mu_psi, sigma_psi = planner.forward(current_state.float(), goal_state.float())\n",
        "      z = torch.normal(mu_psi, sigma_psi)\n",
        "      actor_dist, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "      best_actions = torch.argmax(actor_dist, -1)\n",
        "\n",
        "      #evaluate\n",
        "      for i, action_index in enumerate(best_actions):\n",
        "        if not solved[i]:\n",
        "          cubes[i]._rotate_once(movements[action_index])\n",
        "          steps_taken[i] += 1\n",
        "          if cubes[i].is_done():\n",
        "            solved[i] = True\n",
        "\n",
        "\n",
        "    num_successful = sum(solved)\n",
        "    print(\"Number of successful solves: \", num_successful)\n",
        "\n"
      ],
      "metadata": {
        "id": "_XfezATofIWs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in range(1, 11):\n",
        "  solve_count = 0\n",
        "  for i in range(1000):\n",
        "    moves = attempt_solve(d, 30)\n",
        "    if moves > 0:\n",
        "      solve_count += 1\n",
        "  print(d, \": \", solve_count)\n",
        "\n",
        "solve_count = 0\n",
        "for i in range(1000):\n",
        "  moves = attempt_solve(30, 80)\n",
        "  if moves > 0:\n",
        "    solve_count += 1\n",
        "print(solve_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MinRMH12gTqq",
        "outputId": "ed84c862-1b72-4b5e-dfec-6172bafdd0a7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 :  1000\n",
            "2 :  1000\n",
            "3 :  1000\n",
            "4 :  983\n",
            "5 :  898\n",
            "6 :  802\n",
            "7 :  658\n",
            "8 :  516\n",
            "9 :  379\n",
            "10 :  259\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(attempt_solve(30, 5000))"
      ],
      "metadata": {
        "id": "5wpDN6ug5vvq",
        "outputId": "0df7e7f3-d119-4b67-e1d0-1ee750e7ac60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}