{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKXJKIpgqgNj",
        "outputId": "53e95c28-76eb-48af-91dd-2242ae1ebc8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Connect to Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mImCQYrGqj1j",
        "outputId": "3b6b6fcb-7940-4da2-bfd0-72b6b815f588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DLR/ProjectData\n",
            "Requirement already satisfied: gymnasium[mujoco] in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (4.13.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (0.0.4)\n",
            "Collecting mujoco>=2.1.5 (from gymnasium[mujoco])\n",
            "  Downloading mujoco-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (2.37.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio>=2.14.1->gymnasium[mujoco]) (11.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]) (1.12.2)\n",
            "Collecting glfw (from mujoco>=2.1.5->gymnasium[mujoco])\n",
            "  Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]) (3.1.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]) (3.21.0)\n",
            "Downloading mujoco-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, mujoco\n",
            "Successfully installed glfw-2.8.0 mujoco-3.3.0\n"
          ]
        }
      ],
      "source": [
        "#get to data\n",
        "%cd drive/MyDrive/DLR/ProjectData\n",
        "\n",
        "!pip install gymnasium[mujoco]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3Eu_3Jqu7n",
        "outputId": "c5ec4db8-5e75-4ba0-b322-16cfa71e2d71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, zeros\n",
        "from torch.optim import Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from collections import deque\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNrRIMhErI15",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Visualization code, sampled from HW2\n",
        "#TODO: Set up Ant environment (or other, but ant seemed applicable)\n",
        "import os\n",
        "import gymnasium as gym\n",
        "\n",
        "from gym.wrappers import RecordVideo\n",
        "from IPython.display import Video, display, clear_output\n",
        "\n",
        "# Force MuJoCo to use EGL for rendering (important for Colab)\n",
        "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
        "\n",
        "def visualize(agent, planner):\n",
        "    \"\"\"Visualize agent with a custom camera angle.\"\"\"\n",
        "\n",
        "    # Create environment in rgb_array mode\n",
        "    env = gym.make(\"InvertedPendulum-v5\", render_mode=\"rgb_array\", reset_noise_scale=0.2)\n",
        "\n",
        "    # Apply video recording wrapper\n",
        "    env = RecordVideo(env, video_folder=\"./\", episode_trigger=lambda x: True)\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "\n",
        "    # Access the viewer object through mujoco_py\n",
        "    viewer = env.unwrapped.mujoco_renderer.viewer  # Access viewer\n",
        "    viewer.cam.distance = 3.0     # Set camera distance\n",
        "    viewer.cam.azimuth = 90       # Rotate camera around pendulum\n",
        "    viewer.cam.elevation = 0   # Tilt the camera up/down\n",
        "\n",
        "    hidden_state = None\n",
        "    goal_state = torch.Tensor(obs).to(device)[np.newaxis, :]\n",
        "    for _ in range(16):\n",
        "        plan_mu, plan_sigma = planner.forward(torch.Tensor(obs).to(device)[np.newaxis, :], goal_state)\n",
        "        plan_z = plan_mu + plan_sigma * torch.randn_like(plan_sigma)\n",
        "\n",
        "        for t in range(32):\n",
        "            with torch.no_grad():\n",
        "                actions, hidden_state = agent.forward(torch.Tensor(obs).to(device)[np.newaxis, :], plan_z, goal_state)\n",
        "                actions = actions.squeeze(0)\n",
        "            obs, _, done, _= env.step(actions.cpu().numpy())\n",
        "            if done:\n",
        "                break\n",
        "    env.close()\n",
        "\n",
        "    # Display the latest video\n",
        "    clear_output(wait=True)\n",
        "    display(Video(\"./rl-video-episode-0.mp4\", embed=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgDmi0HJqsuu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "aa8b6f74-1ddf-48de-b0d4-4d545ec63269"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ab635e4deab6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-ab635e4deab6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouped_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m130\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouped_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m130\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "#Getting Data\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self):\n",
        "        files = glob.glob('*.npy')\n",
        "        self.data_list = [np.load(fil) for fil in files]\n",
        "        #list of lists, outer list is each sequence, innerlists contain each step (action state pairs)\n",
        "        self.grouped_data = np.zeros((5, 130, 5))\n",
        "        for i in range(5):\n",
        "            self.grouped_data[i] = self.data_list[i][0:130]\n",
        "\n",
        "    def sample_batch(self, batch_size):\n",
        "        run_num = np.random.randint(0, 5, size=batch_size)\n",
        "        start_indices = np.random.randint(0, 98, size=batch_size)[:, np.newaxis]\n",
        "        indices = start_indices + np.arange(32)[np.newaxis, :]\n",
        "\n",
        "        sample = self.grouped_data[run_num[:, np.newaxis], indices]\n",
        "        return torch.tensor(sample, dtype=torch.float32)\n",
        "\n",
        "data = Dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bZcoy9hsAml"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Actor(nn.Module):\n",
        "    def __init__(self, obs_dim, act_dim, goal_dim, layer_size=1024, latent_dim=256):\n",
        "        super(Actor, self).__init__()\n",
        "\n",
        "        input_dim = obs_dim + latent_dim + goal_dim\n",
        "        self.lstm1 = nn.LSTM(input_dim, layer_size, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(layer_size, layer_size, batch_first=True)\n",
        "\n",
        "        self.actions = nn.Linear(layer_size, act_dim)\n",
        "    # def forward(self, obs, latent_plan, goal, hidden_state=None):\n",
        "    #     x = torch.cat([obs, latent_plan, goal], dim=-1)\n",
        "    def forward(self, obs, z, goal, hidden_state=None):\n",
        "        x = torch.cat([obs, z, goal], dim=-1)\n",
        "\n",
        "        x, hidden_state = self.lstm1(x, hidden_state)\n",
        "        x, hidden_state = self.lstm2(x, hidden_state)\n",
        "\n",
        "        return self.actions(x), hidden_state\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, enc_in_dim, layer_size=2048, latent_dim=256, epsilon=1e-4):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.lstm1 = nn.LSTM(enc_in_dim, layer_size, batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(layer_size * 2, layer_size, batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.mu = nn.Linear(layer_size * 2, latent_dim)\n",
        "        self.sigma = nn.Linear(layer_size * 2, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm1(x)\n",
        "        x, _ = self.lstm2(x)\n",
        "\n",
        "        mu = self.mu(x[:, -1, :])\n",
        "        sigma = F.softplus(self.sigma(x[:, -1, :])) + self.epsilon\n",
        "        # mu = self.mu(x[-1, :])\n",
        "        # sigma = F.softplus(self.sigma(x[-1, :])) + self.epsilon\n",
        "\n",
        "        sample = torch.randn_like(sigma)\n",
        "        z = mu + sigma * sample\n",
        "\n",
        "        return z, mu, sigma\n",
        "\n",
        "class Planner(nn.Module):\n",
        "    def __init__(self, obs_dim, goal_dim, layer_size=2048, latent_dim=256, epsilon=1e-4):\n",
        "        super(Planner, self).__init__()\n",
        "\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        input_dim = obs_dim + goal_dim\n",
        "        self.fc1 = nn.Linear(input_dim, layer_size)\n",
        "        self.fc2 = nn.Linear(layer_size, layer_size)\n",
        "        self.fc3 = nn.Linear(layer_size, layer_size)\n",
        "        self.fc4 = nn.Linear(layer_size, layer_size)\n",
        "\n",
        "        self.mu = nn.Linear(layer_size, latent_dim)\n",
        "        self.sigma = nn.Linear(layer_size, latent_dim)\n",
        "\n",
        "    def forward(self, obs_init, obs_goal):\n",
        "        x = torch.cat([obs_init, obs_goal], dim=-1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "\n",
        "        mu = self.mu(x)\n",
        "        sigma = F.softplus(self.sigma(x)) + self.epsilon\n",
        "\n",
        "        return mu, sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhXfheTXq1sq"
      },
      "outputs": [],
      "source": [
        "import torch.distributions as dist\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_sample(batch_size, beta, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer):\n",
        "    sample = data.sample_batch(batch_size).to(device)\n",
        "    current_state = sample[:, 0, :-1]\n",
        "    current_action = sample[:, 0, -1]\n",
        "    goal_state = sample[:, -1, :-1]\n",
        "    goal_action = sample[:, -1, -1]\n",
        "\n",
        "    z, mu_phi, sigma_phi = encoder.forward(sample)\n",
        "\n",
        "    mu_psi, sigma_psi = planner.forward(current_state, goal_state)\n",
        "\n",
        "    phi_gaussian = dist.Normal(mu_phi, sigma_phi)\n",
        "\n",
        "    psi_gaussian = dist.Normal(mu_psi, sigma_psi)\n",
        "\n",
        "    KL_loss = torch.sum(dist.kl.kl_divergence(phi_gaussian, psi_gaussian))\n",
        "\n",
        "    policy_action, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "    action_loss = F.l1_loss(policy_action.squeeze(1), current_action.unsqueeze(1))\n",
        "\n",
        "    loss = beta * KL_loss + action_loss\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    planner_optimizer.zero_grad()\n",
        "    actor_optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    planner_optimizer.step()\n",
        "    actor_optimizer.step()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 32\n",
        "\n",
        "encoder = Encoder(5, layer_size=256, latent_dim=latent_dim).to(device)\n",
        "planner = Planner(4, 4, layer_size=512, latent_dim=latent_dim).to(device)\n",
        "actor = Actor(4, 1, 4, layer_size=512, latent_dim=latent_dim).to(device)\n",
        "\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-4)\n",
        "planner_optimizer = optim.Adam(planner.parameters(), lr=1e-4)\n",
        "actor_optimizer = optim.Adam(actor.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "RFEaNoJTL-H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KUoZjotGH4n",
        "outputId": "5a39d179-2df7-4441-fc06-8ee157f527db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0, Loss: 3.3969194889068604\n",
            "Batch: 100, Loss: 0.5342366695404053\n",
            "Batch: 200, Loss: 0.2794186770915985\n",
            "Batch: 300, Loss: 0.11472980678081512\n",
            "Batch: 400, Loss: 0.08341763913631439\n",
            "Batch: 500, Loss: 0.10533882677555084\n",
            "Batch: 600, Loss: 0.05830066278576851\n",
            "Batch: 700, Loss: 0.05278594419360161\n",
            "Batch: 800, Loss: 0.04674055799841881\n",
            "Batch: 900, Loss: 0.05848301947116852\n",
            "Batch: 1000, Loss: 0.04381528124213219\n",
            "Batch: 1100, Loss: 0.06324674189090729\n",
            "Batch: 1200, Loss: 0.04114704951643944\n",
            "Batch: 1300, Loss: 0.057159364223480225\n",
            "Batch: 1400, Loss: 0.058317627757787704\n",
            "Batch: 1500, Loss: 0.06413818895816803\n",
            "Batch: 1600, Loss: 0.04789697378873825\n",
            "Batch: 1700, Loss: 0.03897293284535408\n",
            "Batch: 1800, Loss: 0.03721236810088158\n",
            "Batch: 1900, Loss: 0.060143180191516876\n",
            "Batch: 2000, Loss: 0.03714115172624588\n",
            "Batch: 2100, Loss: 0.04689726233482361\n",
            "Batch: 2200, Loss: 0.049595024436712265\n",
            "Batch: 2300, Loss: 0.048318155109882355\n",
            "Batch: 2400, Loss: 0.06195338815450668\n",
            "Batch: 2500, Loss: 0.04466953128576279\n",
            "Batch: 2600, Loss: 0.03559628129005432\n",
            "Batch: 2700, Loss: 0.03482744097709656\n",
            "Batch: 2800, Loss: 0.043090324848890305\n",
            "Batch: 2900, Loss: 0.03774771839380264\n",
            "Batch: 3000, Loss: 0.03777705505490303\n",
            "Batch: 3100, Loss: 0.04198738560080528\n",
            "Batch: 3200, Loss: 0.036688875406980515\n",
            "Batch: 3300, Loss: 0.04477206990122795\n",
            "Batch: 3400, Loss: 0.04879521206021309\n",
            "Batch: 3500, Loss: 0.04129714518785477\n",
            "Batch: 3600, Loss: 0.04981387034058571\n",
            "Batch: 3700, Loss: 0.033583108335733414\n",
            "Batch: 3800, Loss: 0.030061762779951096\n",
            "Batch: 3900, Loss: 0.05209128558635712\n",
            "Batch: 4000, Loss: 0.05771024897694588\n",
            "Batch: 4100, Loss: 0.033309124410152435\n",
            "Batch: 4200, Loss: 0.042164646089076996\n",
            "Batch: 4300, Loss: 0.036938272416591644\n",
            "Batch: 4400, Loss: 0.04207877442240715\n",
            "Batch: 4500, Loss: 0.03070272132754326\n",
            "Batch: 4600, Loss: 0.04819822683930397\n",
            "Batch: 4700, Loss: 0.027102673426270485\n",
            "Batch: 4800, Loss: 0.029210178181529045\n",
            "Batch: 4900, Loss: 0.03847880661487579\n",
            "Batch: 5000, Loss: 0.03044886700809002\n",
            "Batch: 5100, Loss: 0.03226061537861824\n",
            "Batch: 5200, Loss: 0.04269056022167206\n",
            "Batch: 5300, Loss: 0.040376823395490646\n",
            "Batch: 5400, Loss: 0.03764812648296356\n",
            "Batch: 5500, Loss: 0.038423530757427216\n",
            "Batch: 5600, Loss: 0.036443766206502914\n",
            "Batch: 5700, Loss: 0.04060865193605423\n",
            "Batch: 5800, Loss: 0.023649297654628754\n",
            "Batch: 5900, Loss: 0.03290662169456482\n",
            "Batch: 6000, Loss: 0.038330625742673874\n",
            "Batch: 6100, Loss: 0.038083095103502274\n",
            "Batch: 6200, Loss: 0.0392821803689003\n",
            "Batch: 6300, Loss: 0.033298593014478683\n",
            "Batch: 6400, Loss: 0.030725952237844467\n",
            "Batch: 6500, Loss: 0.026561643928289413\n",
            "Batch: 6600, Loss: 0.050474248826503754\n",
            "Batch: 6700, Loss: 0.03492708504199982\n",
            "Batch: 6800, Loss: 0.03452938795089722\n",
            "Batch: 6900, Loss: 0.03510402515530586\n",
            "Batch: 7000, Loss: 0.034048907458782196\n",
            "Batch: 7100, Loss: 0.03534762188792229\n",
            "Batch: 7200, Loss: 0.028525497764348984\n",
            "Batch: 7300, Loss: 0.03306100144982338\n",
            "Batch: 7400, Loss: 0.031690653413534164\n",
            "Batch: 7500, Loss: 0.031428370624780655\n",
            "Batch: 7600, Loss: 0.0341288298368454\n",
            "Batch: 7700, Loss: 0.036662280559539795\n",
            "Batch: 7800, Loss: 0.028524717316031456\n",
            "Batch: 7900, Loss: 0.02361050806939602\n",
            "Batch: 8000, Loss: 0.03625982254743576\n",
            "Batch: 8100, Loss: 0.03010699898004532\n",
            "Batch: 8200, Loss: 0.03289313241839409\n",
            "Batch: 8300, Loss: 0.02348470315337181\n",
            "Batch: 8400, Loss: 0.035965509712696075\n",
            "Batch: 8500, Loss: 0.04106619209051132\n",
            "Batch: 8600, Loss: 0.025733452290296555\n",
            "Batch: 8700, Loss: 0.032476186752319336\n",
            "Batch: 8800, Loss: 0.02669537253677845\n",
            "Batch: 8900, Loss: 0.03798487409949303\n",
            "Batch: 9000, Loss: 0.03180713579058647\n",
            "Batch: 9100, Loss: 0.029965953901410103\n",
            "Batch: 9200, Loss: 0.018752215430140495\n",
            "Batch: 9300, Loss: 0.031162485480308533\n",
            "Batch: 9400, Loss: 0.024800725281238556\n",
            "Batch: 9500, Loss: 0.032607853412628174\n",
            "Batch: 9600, Loss: 0.03640615940093994\n",
            "Batch: 9700, Loss: 0.031897950917482376\n",
            "Batch: 9800, Loss: 0.02586541324853897\n",
            "Batch: 9900, Loss: 0.03399540111422539\n"
          ]
        }
      ],
      "source": [
        "for batch in range(10000):\n",
        "    loss = train_sample(32, .9, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer)\n",
        "    if batch % 100 == 0:\n",
        "        print(f\"Batch: {batch}, Loss: {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "qRZap73DAt7m",
        "outputId": "7676c80d-7389-409d-b288-6846f2259fb7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'visualize' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-72782398e160>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplanner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'visualize' is not defined"
          ]
        }
      ],
      "source": [
        "visualize(actor, planner)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j7hdBgVvwiyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGTz-veB5kMJ"
      },
      "outputs": [],
      "source": [
        "    from google.colab import runtime\n",
        "    runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install magiccube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfQFoZbGwbFH",
        "outputId": "85861f63-040e-4602-af76-64b5b3aab51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting magiccube\n",
            "  Downloading magiccube-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from magiccube) (2.0.2)\n",
            "Downloading magiccube-1.0.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: magiccube\n",
            "Successfully installed magiccube-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import magiccube\n",
        "import copy\n",
        "from magiccube.cube_base import Color, Face\n",
        "from magiccube.cube_move import CubeMove\n",
        "from magiccube.solver.basic.basic_solver import BasicSolver\n",
        "\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "def get_face_state(cube, face):\n",
        "    array_values = np.array([[color.value for color in row] for row in cube.get_face(face)])\n",
        "    tensor = torch.tensor(array_values.flatten(), dtype=torch.int64)\n",
        "    return torch.nn.functional.one_hot(tensor, num_classes=6).flatten()\n",
        "\n",
        "#state space\n",
        "def get_cube_state(cube):\n",
        "    return torch.stack([get_face_state(cube, Face.L), get_face_state(cube, Face.R), get_face_state(cube, Face.D), get_face_state(cube, Face.U), get_face_state(cube, Face.B), get_face_state(cube, Face.F)], dim=0)\n",
        "\n",
        "def batch_cube_state(cube_list):\n",
        "    current_states = []\n",
        "\n",
        "    for cube in cube_list:\n",
        "      current_states.append(get_cube_state(cube))\n",
        "\n",
        "    current_states = torch.stack(current_states)\n",
        "\n",
        "    return current_states.view(current_states.size(0), -1)\n",
        "\n",
        "def batch_apply_action(cube_list, action_list):\n",
        "  for i in range(len(cube_list)):\n",
        "    cube_list[i]._rotate_once(action_list[i])\n",
        "\n",
        "  return cube_list\n",
        "\n",
        "#action space\n",
        "movements = [\"L\", \"L'\", \"L2\", \"R\", \"R'\", \"R2\", \"D\", \"D'\", \"D2\", \"U\", \"U'\", \"U2\", \"B\", \"B'\", \"B2\", \"F\", \"F'\", \"F2\"]\n",
        "reversals = [\"L'\", \"L\", \"L2\", \"R'\", \"R\", \"R2\", \"D'\", \"D\", \"D2\", \"U'\", \"U\", \"U2\", \"B'\", \"B\", \"B2\", \"F'\", \"F\", \"F2\"]\n",
        "reverse_index = {0: 1, 1: 0, 2: 2, 3: 4, 4: 3, 5: 5, 6: 7, 7: 6, 8: 8, 9: 10, 10: 9, 11: 11, 12: 13, 13: 12, 14: 14, 15: 16, 16:15, 17:17}\n",
        "reversals = [CubeMove.create(move_str) for move_str in reversals]\n",
        "movements = [CubeMove.create(move_str) for move_str in movements]\n",
        "print(reversals)\n",
        "\n",
        "cube._rotate_once(movements[8])\n",
        "solver = BasicSolver(cube)\n",
        "cube_copy = copy.deepcopy(cube)\n",
        "solver.solve()\n",
        "\n",
        "for i in range(18):\n",
        "  cube._rotate_once(movements[i])\n",
        "  cube._rotate_once(movements[reverse_index[i]])\n",
        "  print(cube.is_done())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzsAMibJsBvI",
        "outputId": "594843d9-14b5-4093-a54d-8001f5de8320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[L', L, L2, R', R, R2, D', D, D2, U', U, U2, B', B, B2, F', F, F2]\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random move at every step for dataset creation\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100000\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "for i in range(num_samples):\n",
        "  if i % 10000 == 0:\n",
        "    print(f\"Sample: {i}\")\n",
        "  state = get_cube_state(cube).flatten()\n",
        "  data_raw[i, :state_dim] = state\n",
        "\n",
        "  action = random.choice(range(action_dim))\n",
        "  data_raw[i, state_dim + action] = 1\n",
        "\n",
        "  cube._rotate_once(movements[action])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raWpW0b_vkBW",
        "outputId": "9b0815e6-9bbf-4844-d97d-d6ba26d23e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n",
            "Sample: 10000\n",
            "Sample: 20000\n",
            "Sample: 30000\n",
            "Sample: 40000\n",
            "Sample: 50000\n",
            "Sample: 60000\n",
            "Sample: 70000\n",
            "Sample: 80000\n",
            "Sample: 90000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100000\n",
        "move_depth = 4  # Number of forward moves before reversing\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3, \"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "i = 0\n",
        "while i < num_samples:\n",
        "  forward_actions = []\n",
        "  for _ in range(move_depth):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    action = random.choice(range(action_dim))\n",
        "    data_raw[i, state_dim + action] = 1\n",
        "    cube._rotate_once(movements[action])\n",
        "    forward_actions.append(action)\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break\n",
        "\n",
        "  for action in reversed(forward_actions):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    reverse_action = reverse_index[action]\n",
        "    data_raw[i, state_dim + reverse_action] = 1\n",
        "    cube._rotate_once(movements[reverse_action])\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break\n",
        "  if not cube.is_done():\n",
        "    print(\"NOT DONE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj43AWNf5Qx7",
        "outputId": "888cbb72-8822-47a8-b43e-1993c04fd9b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n",
            "Sample: 10000\n",
            "Sample: 20000\n",
            "Sample: 30000\n",
            "Sample: 40000\n",
            "Sample: 50000\n",
            "Sample: 60000\n",
            "Sample: 70000\n",
            "Sample: 80000\n",
            "Sample: 90000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data only contains cubes <= 4 actions away from the goal state\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "#list to store the actual cube objects\n",
        "cube_objects = []\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "for i in range(num_samples):\n",
        "  # print(\"cube \", i)\n",
        "  # print(cube)\n",
        "  if i % 10000 == 0:\n",
        "    print(f\"Sample: {i}\")\n",
        "  if i % 4 == 0:\n",
        "    cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "  state = get_cube_state(cube).flatten()\n",
        "  data_raw[i, :state_dim] = state\n",
        "\n",
        "  action = random.choice(range(action_dim))\n",
        "  data_raw[i, state_dim + action] = 1\n",
        "  cube_objects.append(copy.deepcopy(cube))\n",
        "\n",
        "  cube._rotate_once(movements[action])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fuR4iaekAg5",
        "outputId": "4a8b99da-c82d-4412-9b28-335126dca9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting Data\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, data):\n",
        "        self.data_list = data\n",
        "\n",
        "    def sample_batch(self, batch_size):\n",
        "        start_indices = np.random.randint(0, len(self.data_list) - 32, size=batch_size)[:, np.newaxis]\n",
        "        indices = start_indices + np.arange(32)[np.newaxis, :]\n",
        "\n",
        "        sample = self.data_list[indices]\n",
        "        return sample\n",
        "\n",
        "data = Dataset(data_raw)"
      ],
      "metadata": {
        "id": "pdcQeEuiJld9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_raw[0])\n",
        "print(data_raw.shape)\n",
        "print(cube_objects[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz9momXidF9S",
        "outputId": "34e21872-a65b-4243-fbc6-3951cb89b306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "torch.Size([100000, 342])\n",
            "          Y  Y  Y                   \n",
            "          Y  Y  Y                   \n",
            "          Y  Y  Y                   \n",
            " R  R  R  G  G  G  O  O  O  B  B  B \n",
            " R  R  R  G  G  G  O  O  O  B  B  B \n",
            " R  R  R  G  G  G  O  O  O  B  B  B \n",
            "          W  W  W                   \n",
            "          W  W  W                   \n",
            "          W  W  W                   \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 32\n",
        "\n",
        "encoder = Encoder(state_dim + action_dim, layer_size=256, latent_dim=latent_dim).to(device)\n",
        "planner = Planner(state_dim, state_dim, layer_size=512, latent_dim=latent_dim).to(device)\n",
        "actor = Actor(state_dim, action_dim, state_dim, layer_size=512, latent_dim=latent_dim).to(device)\n",
        "\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-4)\n",
        "planner_optimizer = optim.Adam(planner.parameters(), lr=1e-4)\n",
        "actor_optimizer = optim.Adam(actor.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "dnqS0mJkMbHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.distributions as dist\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_sample(batch_size, beta, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer):\n",
        "    sample = data.sample_batch(batch_size).to(device)\n",
        "    current_state = sample[:, 0, :-18]\n",
        "    current_action = sample[:, 0, -18:]\n",
        "    goal_state = sample[:, -1, :-18]\n",
        "    goal_action = sample[:, -1, -18:]\n",
        "\n",
        "    z, mu_phi, sigma_phi = encoder.forward(sample)\n",
        "    mu_psi, sigma_psi = planner.forward(current_state, goal_state)\n",
        "\n",
        "    phi_gaussian = dist.Normal(mu_phi, sigma_phi)\n",
        "\n",
        "    psi_gaussian = dist.Normal(mu_psi, sigma_psi)\n",
        "\n",
        "    KL_loss = torch.sum(dist.kl.kl_divergence(phi_gaussian, psi_gaussian))\n",
        "\n",
        "    policy_action, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "    action_loss = F.cross_entropy(policy_action.squeeze(1), current_action)\n",
        "\n",
        "    loss = beta * KL_loss + action_loss\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    planner_optimizer.zero_grad()\n",
        "    actor_optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    planner_optimizer.step()\n",
        "    actor_optimizer.step()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Ify5ppGbNxmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in range(10000):\n",
        "    loss = train_sample(32, .9, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer)\n",
        "    if batch % 100 == 0:\n",
        "        print(f\"Batch: {batch}, Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRQTwsBKUjee",
        "outputId": "94fc3432-480d-45c2-f2ef-466ec47b4761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0, Loss: 6.241903305053711\n",
            "Batch: 100, Loss: 2.429344892501831\n",
            "Batch: 200, Loss: 2.1109321117401123\n",
            "Batch: 300, Loss: 1.9098554849624634\n",
            "Batch: 400, Loss: 1.8812134265899658\n",
            "Batch: 500, Loss: 2.522042751312256\n",
            "Batch: 600, Loss: 2.55255126953125\n",
            "Batch: 700, Loss: 2.1031744480133057\n",
            "Batch: 800, Loss: 2.155884027481079\n",
            "Batch: 900, Loss: 2.1561708450317383\n",
            "Batch: 1000, Loss: 2.158642292022705\n",
            "Batch: 1100, Loss: 2.298733711242676\n",
            "Batch: 1200, Loss: 2.0353195667266846\n",
            "Batch: 1300, Loss: 1.9320507049560547\n",
            "Batch: 1400, Loss: 1.8095418214797974\n",
            "Batch: 1500, Loss: 1.973937749862671\n",
            "Batch: 1600, Loss: 2.283557176589966\n",
            "Batch: 1700, Loss: 2.1172311305999756\n",
            "Batch: 1800, Loss: 1.972545862197876\n",
            "Batch: 1900, Loss: 2.67281436920166\n",
            "Batch: 2000, Loss: 1.9489545822143555\n",
            "Batch: 2100, Loss: 2.2429769039154053\n",
            "Batch: 2200, Loss: 2.546633243560791\n",
            "Batch: 2300, Loss: 1.8986903429031372\n",
            "Batch: 2400, Loss: 2.199829578399658\n",
            "Batch: 2500, Loss: 1.777984619140625\n",
            "Batch: 2600, Loss: 2.1823060512542725\n",
            "Batch: 2700, Loss: 2.134422540664673\n",
            "Batch: 2800, Loss: 2.6483991146087646\n",
            "Batch: 2900, Loss: 2.151411294937134\n",
            "Batch: 3000, Loss: 1.6141637563705444\n",
            "Batch: 3100, Loss: 2.0158703327178955\n",
            "Batch: 3200, Loss: 2.0849695205688477\n",
            "Batch: 3300, Loss: 2.409029483795166\n",
            "Batch: 3400, Loss: 2.487488031387329\n",
            "Batch: 3500, Loss: 2.0279064178466797\n",
            "Batch: 3600, Loss: 1.877253532409668\n",
            "Batch: 3700, Loss: 1.9019854068756104\n",
            "Batch: 3800, Loss: 2.0179250240325928\n",
            "Batch: 3900, Loss: 2.0024516582489014\n",
            "Batch: 4000, Loss: 2.157463788986206\n",
            "Batch: 4100, Loss: 2.109588861465454\n",
            "Batch: 4200, Loss: 2.2932674884796143\n",
            "Batch: 4300, Loss: 2.3899993896484375\n",
            "Batch: 4400, Loss: 2.1958770751953125\n",
            "Batch: 4500, Loss: 2.0507500171661377\n",
            "Batch: 4600, Loss: 1.9604769945144653\n",
            "Batch: 4700, Loss: 2.130188465118408\n",
            "Batch: 4800, Loss: 2.0265824794769287\n",
            "Batch: 4900, Loss: 2.153872013092041\n",
            "Batch: 5000, Loss: 1.2709881067276\n",
            "Batch: 5100, Loss: 2.1523325443267822\n",
            "Batch: 5200, Loss: 2.333326816558838\n",
            "Batch: 5300, Loss: 2.0332770347595215\n",
            "Batch: 5400, Loss: 2.4047162532806396\n",
            "Batch: 5500, Loss: 1.9826149940490723\n",
            "Batch: 5600, Loss: 1.925222635269165\n",
            "Batch: 5700, Loss: 2.259202480316162\n",
            "Batch: 5800, Loss: 2.005364418029785\n",
            "Batch: 5900, Loss: 2.0808427333831787\n",
            "Batch: 6000, Loss: 1.885172724723816\n",
            "Batch: 6100, Loss: 2.0875325202941895\n",
            "Batch: 6200, Loss: 2.147129774093628\n",
            "Batch: 6300, Loss: 1.5255098342895508\n",
            "Batch: 6400, Loss: 1.9968924522399902\n",
            "Batch: 6500, Loss: 1.9317857027053833\n",
            "Batch: 6600, Loss: 2.9134576320648193\n",
            "Batch: 6700, Loss: 1.9200059175491333\n",
            "Batch: 6800, Loss: 2.013295888900757\n",
            "Batch: 6900, Loss: 2.0856997966766357\n",
            "Batch: 7000, Loss: 1.891983151435852\n",
            "Batch: 7100, Loss: 2.325472593307495\n",
            "Batch: 7200, Loss: 1.8196464776992798\n",
            "Batch: 7300, Loss: 2.1947362422943115\n",
            "Batch: 7400, Loss: 1.9209873676300049\n",
            "Batch: 7500, Loss: 2.1031811237335205\n",
            "Batch: 7600, Loss: 2.123008966445923\n",
            "Batch: 7700, Loss: 2.0162365436553955\n",
            "Batch: 7800, Loss: 1.5999243259429932\n",
            "Batch: 7900, Loss: 1.7919639348983765\n",
            "Batch: 8000, Loss: 1.907138466835022\n",
            "Batch: 8100, Loss: 2.3900668621063232\n",
            "Batch: 8200, Loss: 1.6272934675216675\n",
            "Batch: 8300, Loss: 1.7551321983337402\n",
            "Batch: 8400, Loss: 1.8812854290008545\n",
            "Batch: 8500, Loss: 1.571677327156067\n",
            "Batch: 8600, Loss: 2.002326488494873\n",
            "Batch: 8700, Loss: 1.9373902082443237\n",
            "Batch: 8800, Loss: 2.447059154510498\n",
            "Batch: 8900, Loss: 1.6918870210647583\n",
            "Batch: 9000, Loss: 2.310230016708374\n",
            "Batch: 9100, Loss: 1.707265853881836\n",
            "Batch: 9200, Loss: 2.4749562740325928\n",
            "Batch: 9300, Loss: 2.2187130451202393\n",
            "Batch: 9400, Loss: 2.2541048526763916\n",
            "Batch: 9500, Loss: 2.261430501937866\n",
            "Batch: 9600, Loss: 1.8378715515136719\n",
            "Batch: 9700, Loss: 2.1694164276123047\n",
            "Batch: 9800, Loss: 1.6840767860412598\n",
            "Batch: 9900, Loss: 2.3069565296173096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.distributions as dist\n",
        "import torch.optim as optim\n",
        "\n",
        "move_dict =  {\"L\": 0,\n",
        "              \"L'\": 1,\n",
        "              \"L2\": 2,\n",
        "              \"R\": 3,\n",
        "              \"R'\": 4,\n",
        "              \"R2\": 5,\n",
        "              \"D\": 6,\n",
        "              \"D'\": 7,\n",
        "              \"D2\": 8,\n",
        "              \"U\": 9,\n",
        "              \"U'\": 10,\n",
        "              \"U2\": 11,\n",
        "              \"B\": 12,\n",
        "              \"B'\": 13,\n",
        "              \"B2\": 14,\n",
        "              \"F\": 15,\n",
        "              \"F'\": 16,\n",
        "              \"F2\": 17\n",
        "              }\n",
        "\n",
        "def generate_training_data(set_size, num_moves):\n",
        "    cubes = []\n",
        "    actions = []\n",
        "    states = []\n",
        "    data = []\n",
        "\n",
        "    for i in range(set_size):\n",
        "      cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "      history = cube.scramble(num_moves)\n",
        "      to_solve = copy.deepcopy(cube)\n",
        "      to_get_states = copy.deepcopy(cube)\n",
        "\n",
        "      solver = BasicSolver(to_solve)\n",
        "      solve = solver.solve()\n",
        "\n",
        "      raw_actions = torch.zeros((len(solve), 18))\n",
        "\n",
        "      raw_states = [get_cube_state(cube)]\n",
        "      # instead of having states and actions separate, they should be hstacked into one tensor\n",
        "      for j in range(len(solve)):\n",
        "        to_get_states._rotate_once(solve[j])\n",
        "        raw_states.append(get_cube_state(to_get_states).flatten())\n",
        "        raw_actions[j, move_dict[str(solve[j])]] = 1\n",
        "\n",
        "      for sample, action in zip(raw_states, raw_actions):\n",
        "        sample = sample.view(-1)\n",
        "        action = action.view(-1)\n",
        "        data.append(torch.hstack((action, sample)))\n",
        "\n",
        "      cubes.append(cube)\n",
        "      actions.append(raw_actions)\n",
        "      states.append(raw_states)\n",
        "\n",
        "    actions = torch.stack(actions)\n",
        "    states = torch.stack(states)\n",
        "\n",
        "    stacked = torch.hstack((actions, states))\n",
        "\n",
        "    return cubes, data\n",
        "\n",
        "\n",
        "def train_sample(batch_size, beta, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer):\n",
        "    #can use this logic to get the elements we need\n",
        "    # iterate so that we train for each step in the soling process\n",
        "\n",
        "    # sample = data.sample_batch(batch_size).to(device)\n",
        "    # current_state = sample[:, 0, :-18]\n",
        "    # current_action = sample[:, 0, -18:]\n",
        "    # goal_state = sample[:, -1, :-18]\n",
        "    # goal_action = sample[:, -1, -18:]\n",
        "\n",
        "    cubes, data = generate_training_data(batch_size, 1)\n",
        "    data_tensor = torch.stack(data).to(device)\n",
        "    states = data_tensor[:, :, :-18]\n",
        "    actions = data_tensor[:, :, -18:]\n",
        "\n",
        "    goal_cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "    goal_state = get_cube_state(goal_cube)\n",
        "    goal_state = goal_state.unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n",
        "    goal_state = goal_state.view(goal_state.size(0), -1)\n",
        "\n",
        "    print(states[0][0].flatten())\n",
        "\n",
        "\n",
        "    current_state = states[:, 0]\n",
        "    current_action = actions[:, 0]\n",
        "\n",
        "    sample = torch.hstack(states, actions)\n",
        "\n",
        "\n",
        "    z, mu_phi, sigma_phi = encoder.forward(sample)\n",
        "    mu_psi, sigma_psi = planner.forward(current_state, goal_state)\n",
        "\n",
        "    phi_gaussian = dist.Normal(mu_phi, sigma_phi)\n",
        "\n",
        "    psi_gaussian = dist.Normal(mu_psi, sigma_psi)\n",
        "\n",
        "    KL_loss = torch.sum(dist.kl.kl_divergence(phi_gaussian, psi_gaussian))\n",
        "\n",
        "    policy_action, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "    action_loss = F.cross_entropy(policy_action.squeeze(1), current_action)\n",
        "\n",
        "    loss = beta * KL_loss + action_loss\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    planner_optimizer.zero_grad()\n",
        "    actor_optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    planner_optimizer.step()\n",
        "    actor_optimizer.step()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "V9hUAvG0wPd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in range(10000):\n",
        "    loss = train_sample(32, .9, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer)\n",
        "    if batch % 100 == 0:\n",
        "        print(f\"Batch: {batch}, Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "A_nakqzewRX0",
        "outputId": "3539072f-c381-4754-bc02-844f53077877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [1, 18] at entry 0 and [109, 18] at entry 12",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-d1d718d237b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplanner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplanner_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Batch: {batch}, Loss: {loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-bf5f262405b6>\u001b[0m in \u001b[0;36mtrain_sample\u001b[0;34m(batch_size, beta, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# goal_action = sample[:, -1, -18:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mcubes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mdata_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-bf5f262405b6>\u001b[0m in \u001b[0;36mgenerate_training_data\u001b[0;34m(set_size, num_moves)\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 18] at entry 0 and [109, 18] at entry 12"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_batch(batch_size):\n",
        "\n",
        "    cubes = []\n",
        "    histories = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "      history = cube.scramble(1)\n",
        "\n",
        "      cubes.append(cube)\n",
        "      histories.append(history)\n",
        "\n",
        "    return cubes, histories\n",
        "\n",
        "def test_sample(batch_size, encoder, actor, planner):\n",
        "\n",
        "    goal_cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "    goal_state = get_cube_state(goal_cube)\n",
        "    goal_state = goal_state.unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n",
        "    goal_state = goal_state.view(goal_state.size(0), -1)\n",
        "\n",
        "    cubes, histories = test_batch(batch_size)\n",
        "\n",
        "    solved = [False] * batch_size\n",
        "    steps_taken = [0] * batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "      current_state = batch_cube_state(cubes).to(device)\n",
        "\n",
        "      mu_psi, sigma_psi = planner.forward(current_state.float(), goal_state.float())\n",
        "      z = torch.normal(mu_psi, sigma_psi)\n",
        "      actor_dist, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "      best_actions = torch.argmax(actor_dist, -1)\n",
        "\n",
        "      #evaluate\n",
        "      for i, action_index in enumerate(best_actions):\n",
        "        if not solved[i]:\n",
        "          cubes[i]._rotate_once(movements[action_index])\n",
        "          steps_taken[i] += 1\n",
        "          if cubes[i].is_done():\n",
        "            solved[i] = True\n",
        "\n",
        "\n",
        "    num_successful = sum(solved)\n",
        "    print(\"Number of successful solves: \", num_successful)\n",
        "\n"
      ],
      "metadata": {
        "id": "_XfezATofIWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample(32, encoder, actor, planner)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MinRMH12gTqq",
        "outputId": "729087f4-4fde-4854-fe5c-377f122e4c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successful solves:  32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ozSgikIYZpFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b071f257-fe32-4d2c-db9d-80ab080abdfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}