{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PieBob851/LfP-Rubix-Cube.git\n",
        "%cd LfP-Rubix-Cube"
      ],
      "metadata": {
        "id": "Wcdoe1095pLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3Eu_3Jqu7n",
        "outputId": "c5ec4db8-5e75-4ba0-b322-16cfa71e2d71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from utils import train_sample\n",
        "from model.encoder import Encoder\n",
        "from model.planner import Planner\n",
        "from model.actor import Actor\n",
        "import torch\n",
        "from torch import nn, zeros\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from collections import deque\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install magiccube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfQFoZbGwbFH",
        "outputId": "85861f63-040e-4602-af76-64b5b3aab51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting magiccube\n",
            "  Downloading magiccube-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from magiccube) (2.0.2)\n",
            "Downloading magiccube-1.0.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: magiccube\n",
            "Successfully installed magiccube-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import magiccube\n",
        "import copy\n",
        "from magiccube.cube_base import Color, Face\n",
        "from magiccube.cube_move import CubeMove\n",
        "from magiccube.solver.basic.basic_solver import BasicSolver\n",
        "\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "def get_face_state(cube, face):\n",
        "    array_values = np.array([[color.value for color in row] for row in cube.get_face(face)])\n",
        "    tensor = torch.tensor(array_values.flatten(), dtype=torch.int64)\n",
        "    return torch.nn.functional.one_hot(tensor, num_classes=6).flatten()\n",
        "\n",
        "#state space\n",
        "def get_cube_state(cube):\n",
        "    return torch.stack([get_face_state(cube, Face.L), get_face_state(cube, Face.R), get_face_state(cube, Face.D), get_face_state(cube, Face.U), get_face_state(cube, Face.B), get_face_state(cube, Face.F)], dim=0)\n",
        "\n",
        "def batch_cube_state(cube_list):\n",
        "    current_states = []\n",
        "\n",
        "    for cube in cube_list:\n",
        "      current_states.append(get_cube_state(cube))\n",
        "\n",
        "    current_states = torch.stack(current_states)\n",
        "\n",
        "    return current_states.view(current_states.size(0), -1)\n",
        "\n",
        "def batch_apply_action(cube_list, action_list):\n",
        "  for i in range(len(cube_list)):\n",
        "    cube_list[i]._rotate_once(action_list[i])\n",
        "\n",
        "  return cube_list\n",
        "\n",
        "#action space\n",
        "movements = [\"L\", \"L'\", \"L2\", \"R\", \"R'\", \"R2\", \"D\", \"D'\", \"D2\", \"U\", \"U'\", \"U2\", \"B\", \"B'\", \"B2\", \"F\", \"F'\", \"F2\"]\n",
        "reversals = [\"L'\", \"L\", \"L2\", \"R'\", \"R\", \"R2\", \"D'\", \"D\", \"D2\", \"U'\", \"U\", \"U2\", \"B'\", \"B\", \"B2\", \"F'\", \"F\", \"F2\"]\n",
        "reverse_index = {0: 1, 1: 0, 2: 2, 3: 4, 4: 3, 5: 5, 6: 7, 7: 6, 8: 8, 9: 10, 10: 9, 11: 11, 12: 13, 13: 12, 14: 14, 15: 16, 16:15, 17:17}\n",
        "reversals = [CubeMove.create(move_str) for move_str in reversals]\n",
        "movements = [CubeMove.create(move_str) for move_str in movements]\n",
        "\n",
        "cube._rotate_once(movements[8])\n",
        "solver = BasicSolver(cube)\n",
        "cube_copy = copy.deepcopy(cube)\n",
        "solver.solve()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzsAMibJsBvI",
        "outputId": "594843d9-14b5-4093-a54d-8001f5de8320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[L', L, L2, R', R, R2, D', D, D2, U', U, U2, B', B, B2, F', F, F2]\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random move at every step for dataset creation\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100000\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "for i in range(num_samples):\n",
        "  if i % 10000 == 0:\n",
        "    print(f\"Sample: {i}\")\n",
        "  state = get_cube_state(cube).flatten()\n",
        "  data_raw[i, :state_dim] = state\n",
        "\n",
        "  action = random.choice(range(action_dim))\n",
        "  data_raw[i, state_dim + action] = 1\n",
        "\n",
        "  cube._rotate_once(movements[action])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raWpW0b_vkBW",
        "outputId": "9b0815e6-9bbf-4844-d97d-d6ba26d23e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n",
            "Sample: 10000\n",
            "Sample: 20000\n",
            "Sample: 30000\n",
            "Sample: 40000\n",
            "Sample: 50000\n",
            "Sample: 60000\n",
            "Sample: 70000\n",
            "Sample: 80000\n",
            "Sample: 90000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# forward set number of moves, before reversing\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100000\n",
        "move_depth = 4  # Number of forward moves before reversing\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3, \"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "i = 0\n",
        "while i < num_samples:\n",
        "  forward_actions = []\n",
        "  for _ in range(move_depth):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    action = random.choice(range(action_dim))\n",
        "    data_raw[i, state_dim + action] = 1\n",
        "    cube._rotate_once(movements[action])\n",
        "    forward_actions.append(action)\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break\n",
        "\n",
        "  for action in reversed(forward_actions):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    reverse_action = reverse_index[action]\n",
        "    data_raw[i, state_dim + reverse_action] = 1\n",
        "    cube._rotate_once(movements[reverse_action])\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj43AWNf5Qx7",
        "outputId": "888cbb72-8822-47a8-b43e-1993c04fd9b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n",
            "Sample: 10000\n",
            "Sample: 20000\n",
            "Sample: 30000\n",
            "Sample: 40000\n",
            "Sample: 50000\n",
            "Sample: 60000\n",
            "Sample: 70000\n",
            "Sample: 80000\n",
            "Sample: 90000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting Data\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, data):\n",
        "        self.data_list = data\n",
        "\n",
        "    def sample_batch(self, batch_size):\n",
        "        start_indices = np.random.randint(0, len(self.data_list) - 32, size=batch_size)[:, np.newaxis]\n",
        "        indices = start_indices + np.arange(32)[np.newaxis, :]\n",
        "\n",
        "        sample = self.data_list[indices]\n",
        "        return sample\n",
        "\n",
        "data = Dataset(data_raw)"
      ],
      "metadata": {
        "id": "pdcQeEuiJld9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 32\n",
        "\n",
        "encoder = Encoder(state_dim + action_dim, layer_size=256, latent_dim=latent_dim).to(device)\n",
        "planner = Planner(state_dim, state_dim, layer_size=512, latent_dim=latent_dim).to(device)\n",
        "actor = Actor(state_dim, action_dim, state_dim, layer_size=512, latent_dim=latent_dim).to(device)\n",
        "\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-4)\n",
        "planner_optimizer = optim.Adam(planner.parameters(), lr=1e-4)\n",
        "actor_optimizer = optim.Adam(actor.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "dnqS0mJkMbHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in range(10000):\n",
        "    loss = train_sample(32, .9, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer)\n",
        "    if batch % 100 == 0:\n",
        "        print(f\"Batch: {batch}, Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRQTwsBKUjee",
        "outputId": "94fc3432-480d-45c2-f2ef-466ec47b4761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0, Loss: 6.241903305053711\n",
            "Batch: 100, Loss: 2.429344892501831\n",
            "Batch: 200, Loss: 2.1109321117401123\n",
            "Batch: 300, Loss: 1.9098554849624634\n",
            "Batch: 400, Loss: 1.8812134265899658\n",
            "Batch: 500, Loss: 2.522042751312256\n",
            "Batch: 600, Loss: 2.55255126953125\n",
            "Batch: 700, Loss: 2.1031744480133057\n",
            "Batch: 800, Loss: 2.155884027481079\n",
            "Batch: 900, Loss: 2.1561708450317383\n",
            "Batch: 1000, Loss: 2.158642292022705\n",
            "Batch: 1100, Loss: 2.298733711242676\n",
            "Batch: 1200, Loss: 2.0353195667266846\n",
            "Batch: 1300, Loss: 1.9320507049560547\n",
            "Batch: 1400, Loss: 1.8095418214797974\n",
            "Batch: 1500, Loss: 1.973937749862671\n",
            "Batch: 1600, Loss: 2.283557176589966\n",
            "Batch: 1700, Loss: 2.1172311305999756\n",
            "Batch: 1800, Loss: 1.972545862197876\n",
            "Batch: 1900, Loss: 2.67281436920166\n",
            "Batch: 2000, Loss: 1.9489545822143555\n",
            "Batch: 2100, Loss: 2.2429769039154053\n",
            "Batch: 2200, Loss: 2.546633243560791\n",
            "Batch: 2300, Loss: 1.8986903429031372\n",
            "Batch: 2400, Loss: 2.199829578399658\n",
            "Batch: 2500, Loss: 1.777984619140625\n",
            "Batch: 2600, Loss: 2.1823060512542725\n",
            "Batch: 2700, Loss: 2.134422540664673\n",
            "Batch: 2800, Loss: 2.6483991146087646\n",
            "Batch: 2900, Loss: 2.151411294937134\n",
            "Batch: 3000, Loss: 1.6141637563705444\n",
            "Batch: 3100, Loss: 2.0158703327178955\n",
            "Batch: 3200, Loss: 2.0849695205688477\n",
            "Batch: 3300, Loss: 2.409029483795166\n",
            "Batch: 3400, Loss: 2.487488031387329\n",
            "Batch: 3500, Loss: 2.0279064178466797\n",
            "Batch: 3600, Loss: 1.877253532409668\n",
            "Batch: 3700, Loss: 1.9019854068756104\n",
            "Batch: 3800, Loss: 2.0179250240325928\n",
            "Batch: 3900, Loss: 2.0024516582489014\n",
            "Batch: 4000, Loss: 2.157463788986206\n",
            "Batch: 4100, Loss: 2.109588861465454\n",
            "Batch: 4200, Loss: 2.2932674884796143\n",
            "Batch: 4300, Loss: 2.3899993896484375\n",
            "Batch: 4400, Loss: 2.1958770751953125\n",
            "Batch: 4500, Loss: 2.0507500171661377\n",
            "Batch: 4600, Loss: 1.9604769945144653\n",
            "Batch: 4700, Loss: 2.130188465118408\n",
            "Batch: 4800, Loss: 2.0265824794769287\n",
            "Batch: 4900, Loss: 2.153872013092041\n",
            "Batch: 5000, Loss: 1.2709881067276\n",
            "Batch: 5100, Loss: 2.1523325443267822\n",
            "Batch: 5200, Loss: 2.333326816558838\n",
            "Batch: 5300, Loss: 2.0332770347595215\n",
            "Batch: 5400, Loss: 2.4047162532806396\n",
            "Batch: 5500, Loss: 1.9826149940490723\n",
            "Batch: 5600, Loss: 1.925222635269165\n",
            "Batch: 5700, Loss: 2.259202480316162\n",
            "Batch: 5800, Loss: 2.005364418029785\n",
            "Batch: 5900, Loss: 2.0808427333831787\n",
            "Batch: 6000, Loss: 1.885172724723816\n",
            "Batch: 6100, Loss: 2.0875325202941895\n",
            "Batch: 6200, Loss: 2.147129774093628\n",
            "Batch: 6300, Loss: 1.5255098342895508\n",
            "Batch: 6400, Loss: 1.9968924522399902\n",
            "Batch: 6500, Loss: 1.9317857027053833\n",
            "Batch: 6600, Loss: 2.9134576320648193\n",
            "Batch: 6700, Loss: 1.9200059175491333\n",
            "Batch: 6800, Loss: 2.013295888900757\n",
            "Batch: 6900, Loss: 2.0856997966766357\n",
            "Batch: 7000, Loss: 1.891983151435852\n",
            "Batch: 7100, Loss: 2.325472593307495\n",
            "Batch: 7200, Loss: 1.8196464776992798\n",
            "Batch: 7300, Loss: 2.1947362422943115\n",
            "Batch: 7400, Loss: 1.9209873676300049\n",
            "Batch: 7500, Loss: 2.1031811237335205\n",
            "Batch: 7600, Loss: 2.123008966445923\n",
            "Batch: 7700, Loss: 2.0162365436553955\n",
            "Batch: 7800, Loss: 1.5999243259429932\n",
            "Batch: 7900, Loss: 1.7919639348983765\n",
            "Batch: 8000, Loss: 1.907138466835022\n",
            "Batch: 8100, Loss: 2.3900668621063232\n",
            "Batch: 8200, Loss: 1.6272934675216675\n",
            "Batch: 8300, Loss: 1.7551321983337402\n",
            "Batch: 8400, Loss: 1.8812854290008545\n",
            "Batch: 8500, Loss: 1.571677327156067\n",
            "Batch: 8600, Loss: 2.002326488494873\n",
            "Batch: 8700, Loss: 1.9373902082443237\n",
            "Batch: 8800, Loss: 2.447059154510498\n",
            "Batch: 8900, Loss: 1.6918870210647583\n",
            "Batch: 9000, Loss: 2.310230016708374\n",
            "Batch: 9100, Loss: 1.707265853881836\n",
            "Batch: 9200, Loss: 2.4749562740325928\n",
            "Batch: 9300, Loss: 2.2187130451202393\n",
            "Batch: 9400, Loss: 2.2541048526763916\n",
            "Batch: 9500, Loss: 2.261430501937866\n",
            "Batch: 9600, Loss: 1.8378715515136719\n",
            "Batch: 9700, Loss: 2.1694164276123047\n",
            "Batch: 9800, Loss: 1.6840767860412598\n",
            "Batch: 9900, Loss: 2.3069565296173096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_batch(batch_size):\n",
        "\n",
        "    cubes = []\n",
        "    histories = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "      history = cube.scramble(1)\n",
        "\n",
        "      cubes.append(cube)\n",
        "      histories.append(history)\n",
        "\n",
        "    return cubes, histories\n",
        "\n",
        "def test_sample(batch_size, encoder, actor, planner):\n",
        "\n",
        "    goal_cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "    goal_state = get_cube_state(goal_cube)\n",
        "    goal_state = goal_state.unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n",
        "    goal_state = goal_state.view(goal_state.size(0), -1)\n",
        "\n",
        "    cubes, histories = test_batch(batch_size)\n",
        "\n",
        "    solved = [False] * batch_size\n",
        "    steps_taken = [0] * batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "      current_state = batch_cube_state(cubes).to(device)\n",
        "\n",
        "      mu_psi, sigma_psi = planner.forward(current_state.float(), goal_state.float())\n",
        "      z = torch.normal(mu_psi, sigma_psi)\n",
        "      actor_dist, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "      best_actions = torch.argmax(actor_dist, -1)\n",
        "\n",
        "      #evaluate\n",
        "      for i, action_index in enumerate(best_actions):\n",
        "        if not solved[i]:\n",
        "          cubes[i]._rotate_once(movements[action_index])\n",
        "          steps_taken[i] += 1\n",
        "          if cubes[i].is_done():\n",
        "            solved[i] = True\n",
        "\n",
        "\n",
        "    num_successful = sum(solved)\n",
        "    print(\"Number of successful solves: \", num_successful)\n",
        "\n"
      ],
      "metadata": {
        "id": "_XfezATofIWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample(32, encoder, actor, planner)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MinRMH12gTqq",
        "outputId": "729087f4-4fde-4854-fe5c-377f122e4c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successful solves:  32\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}