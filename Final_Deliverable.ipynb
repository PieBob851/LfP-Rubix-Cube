{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "!git clone https://github.com/PieBob851/LfP-Rubix-Cube.git\n",
        "%cd LfP-Rubix-Cube"
      ],
      "metadata": {
        "id": "Wcdoe1095pLo",
        "outputId": "943c7ea8-f8c1-4df3-c849-8f8228404e16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "Cloning into 'LfP-Rubix-Cube'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 30 (delta 12), reused 21 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (30/30), 16.44 KiB | 5.48 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "/LfP-Rubix-Cube\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Utils\n"
      ],
      "metadata": {
        "id": "5kZB5Lcq9uDc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3Eu_3Jqu7n",
        "outputId": "18967b39-231f-4a53-93b6-fdcfbc908b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from model.encoder import Encoder\n",
        "from model.planner import Planner\n",
        "from model.actor import Actor\n",
        "import torch\n",
        "from torch import nn, zeros\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from collections import deque\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install magiccube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfQFoZbGwbFH",
        "outputId": "02619288-9f68-4e94-d47b-de99279ec1c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting magiccube\n",
            "  Downloading magiccube-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from magiccube) (2.0.2)\n",
            "Downloading magiccube-1.0.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: magiccube\n",
            "Successfully installed magiccube-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import magiccube\n",
        "import copy\n",
        "from magiccube.cube_base import Color, Face\n",
        "from magiccube.cube_move import CubeMove\n",
        "from magiccube.solver.basic.basic_solver import BasicSolver\n",
        "\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "def get_face_state(cube, face):\n",
        "    array_values = np.array([[color.value for color in row] for row in cube.get_face(face)])\n",
        "    tensor = torch.tensor(array_values.flatten(), dtype=torch.int64)\n",
        "    return torch.nn.functional.one_hot(tensor, num_classes=6).flatten()\n",
        "\n",
        "#state space\n",
        "def get_cube_state(cube):\n",
        "    return torch.stack([get_face_state(cube, Face.L), get_face_state(cube, Face.R), get_face_state(cube, Face.D), get_face_state(cube, Face.U), get_face_state(cube, Face.B), get_face_state(cube, Face.F)], dim=0)\n",
        "\n",
        "def batch_cube_state(cube_list):\n",
        "    current_states = []\n",
        "\n",
        "    for cube in cube_list:\n",
        "      current_states.append(get_cube_state(cube))\n",
        "\n",
        "    current_states = torch.stack(current_states)\n",
        "\n",
        "    return current_states.view(current_states.size(0), -1)\n",
        "\n",
        "def batch_apply_action(cube_list, action_list):\n",
        "  for i in range(len(cube_list)):\n",
        "    cube_list[i]._rotate_once(action_list[i])\n",
        "\n",
        "  return cube_list\n",
        "\n",
        "#action space\n",
        "movements = [\"L\", \"L'\", \"L2\", \"R\", \"R'\", \"R2\", \"D\", \"D'\", \"D2\", \"U\", \"U'\", \"U2\", \"B\", \"B'\", \"B2\", \"F\", \"F'\", \"F2\"]\n",
        "reversals = [\"L'\", \"L\", \"L2\", \"R'\", \"R\", \"R2\", \"D'\", \"D\", \"D2\", \"U'\", \"U\", \"U2\", \"B'\", \"B\", \"B2\", \"F'\", \"F\", \"F2\"]\n",
        "reverse_index = {0: 1, 1: 0, 2: 2, 3: 4, 4: 3, 5: 5, 6: 7, 7: 6, 8: 8, 9: 10, 10: 9, 11: 11, 12: 13, 13: 12, 14: 14, 15: 16, 16:15, 17:17}\n",
        "reversals = [CubeMove.create(move_str) for move_str in reversals]\n",
        "movements = [CubeMove.create(move_str) for move_str in movements]\n",
        "\n",
        "# cube._rotate_once(movements[8])\n",
        "# solver = BasicSolver(cube)\n",
        "# cube_copy = copy.deepcopy(cube)\n",
        "# solver.solve()"
      ],
      "metadata": {
        "id": "BzsAMibJsBvI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection\n",
        "\n",
        "Different ways to collect data (only one should be used)"
      ],
      "metadata": {
        "id": "l0gooVAu97L4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random move selection - at every timestep, a random move is chosen"
      ],
      "metadata": {
        "id": "a317An1e-8Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random move at every step for dataset creation\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100000\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "for i in range(num_samples):\n",
        "  if i % 10000 == 0:\n",
        "    print(f\"Sample: {i}\")\n",
        "  state = get_cube_state(cube).flatten()\n",
        "  data_raw[i, :state_dim] = state\n",
        "\n",
        "  action = random.choice(range(action_dim))\n",
        "  data_raw[i, state_dim + action] = 1\n",
        "\n",
        "  cube._rotate_once(movements[action])"
      ],
      "metadata": {
        "id": "raWpW0b_vkBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random move selection with reversing - starts with a solved cube, then advances move_depth steps forward with random move selection. After this, it reverses those moves (so the cube is once again solved)."
      ],
      "metadata": {
        "id": "U2ZakNFh_DTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# forward set number of moves, before reversing\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100000\n",
        "move_depth = 16  # Number of forward moves before reversing\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3, \"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "i = 0\n",
        "while i < num_samples:\n",
        "  forward_actions = []\n",
        "  for _ in range(move_depth):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    action = random.choice(range(action_dim))\n",
        "    data_raw[i, state_dim + action] = 1\n",
        "    cube._rotate_once(movements[action])\n",
        "    forward_actions.append(action)\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break\n",
        "\n",
        "  for action in reversed(forward_actions):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    reverse_action = reverse_index[action]\n",
        "    data_raw[i, state_dim + reverse_action] = 1\n",
        "    cube._rotate_once(movements[reverse_action])\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj43AWNf5Qx7",
        "outputId": "87146e51-c869-46f5-d6ec-7ecf28b5bcdd"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n",
            "Sample: 10000\n",
            "Sample: 20000\n",
            "Sample: 30000\n",
            "Sample: 40000\n",
            "Sample: 50000\n",
            "Sample: 60000\n",
            "Sample: 70000\n",
            "Sample: 80000\n",
            "Sample: 90000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting Data\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, data):\n",
        "        self.data_list = data\n",
        "\n",
        "    def sample_batch(self, batch_size):\n",
        "        start_indices = np.random.randint(0, len(self.data_list) - 32, size=batch_size)[:, np.newaxis]\n",
        "        indices = start_indices + np.arange(32)[np.newaxis, :]\n",
        "\n",
        "        sample = self.data_list[indices]\n",
        "        return sample\n",
        "\n",
        "data = Dataset(data_raw)"
      ],
      "metadata": {
        "id": "pdcQeEuiJld9"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 32\n",
        "\n",
        "encoder = Encoder(state_dim + action_dim, layer_size=256, latent_dim=latent_dim).to(device)\n",
        "planner = Planner(state_dim, state_dim, layer_size=512, latent_dim=latent_dim).to(device)\n",
        "actor = Actor(state_dim, action_dim, state_dim, layer_size=512, latent_dim=latent_dim).to(device)\n",
        "\n",
        "encoder_optimizer = Adam(encoder.parameters(), lr=1e-4)\n",
        "planner_optimizer = Adam(planner.parameters(), lr=1e-4)\n",
        "actor_optimizer = Adam(actor.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "dnqS0mJkMbHd"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing\n"
      ],
      "metadata": {
        "id": "Mgt8MyeA-ElT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.distributions as dist\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_sample(batch_size, beta, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer, data):\n",
        "    sample = data.sample_batch(batch_size).to(device)\n",
        "    current_state = sample[:, 0, :-18]\n",
        "    current_action = sample[:, 0, -18:]\n",
        "    goal_state = sample[:, -1, :-18]\n",
        "    goal_action = sample[:, -1, -18:]\n",
        "\n",
        "    z, mu_phi, sigma_phi = encoder.forward(sample)\n",
        "    mu_psi, sigma_psi = planner.forward(current_state, goal_state)\n",
        "\n",
        "    phi_gaussian = dist.Normal(mu_phi, sigma_phi)\n",
        "\n",
        "    psi_gaussian = dist.Normal(mu_psi, sigma_psi)\n",
        "\n",
        "    KL_loss = torch.sum(dist.kl.kl_divergence(phi_gaussian, psi_gaussian))\n",
        "\n",
        "    policy_action, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "    action_loss = F.cross_entropy(policy_action.squeeze(1), current_action)\n",
        "\n",
        "    loss = beta * KL_loss + action_loss\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    planner_optimizer.zero_grad()\n",
        "    actor_optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    planner_optimizer.step()\n",
        "    actor_optimizer.step()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "V2A3_IwZB1js"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in range(10000):\n",
        "    loss = train_sample(32, .9, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer, data)\n",
        "    if batch % 100 == 0:\n",
        "        print(f\"Batch: {batch}, Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRQTwsBKUjee",
        "outputId": "e030e529-1f4d-4182-c043-81aaa2d71a3a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0, Loss: 2.459994077682495\n",
            "Batch: 100, Loss: 2.170710325241089\n",
            "Batch: 200, Loss: 2.324516773223877\n",
            "Batch: 300, Loss: 2.1151669025421143\n",
            "Batch: 400, Loss: 2.2925820350646973\n",
            "Batch: 500, Loss: 2.1892924308776855\n",
            "Batch: 600, Loss: 2.4081637859344482\n",
            "Batch: 700, Loss: 2.4754228591918945\n",
            "Batch: 800, Loss: 2.2413723468780518\n",
            "Batch: 900, Loss: 2.3385369777679443\n",
            "Batch: 1000, Loss: 2.183824300765991\n",
            "Batch: 1100, Loss: 2.314997673034668\n",
            "Batch: 1200, Loss: 2.413665771484375\n",
            "Batch: 1300, Loss: 2.1310625076293945\n",
            "Batch: 1400, Loss: 1.9714117050170898\n",
            "Batch: 1500, Loss: 2.043861150741577\n",
            "Batch: 1600, Loss: 1.997283697128296\n",
            "Batch: 1700, Loss: 2.427172899246216\n",
            "Batch: 1800, Loss: 2.5488486289978027\n",
            "Batch: 1900, Loss: 2.0462987422943115\n",
            "Batch: 2000, Loss: 2.1164121627807617\n",
            "Batch: 2100, Loss: 2.2649433612823486\n",
            "Batch: 2200, Loss: 2.1639907360076904\n",
            "Batch: 2300, Loss: 2.4047627449035645\n",
            "Batch: 2400, Loss: 2.265184164047241\n",
            "Batch: 2500, Loss: 1.9608955383300781\n",
            "Batch: 2600, Loss: 2.4325337409973145\n",
            "Batch: 2700, Loss: 2.1698124408721924\n",
            "Batch: 2800, Loss: 2.249558687210083\n",
            "Batch: 2900, Loss: 2.293142557144165\n",
            "Batch: 3000, Loss: 1.839068055152893\n",
            "Batch: 3100, Loss: 2.412531852722168\n",
            "Batch: 3200, Loss: 1.9481168985366821\n",
            "Batch: 3300, Loss: 2.2731382846832275\n",
            "Batch: 3400, Loss: 1.77082359790802\n",
            "Batch: 3500, Loss: 2.418518543243408\n",
            "Batch: 3600, Loss: 2.8184475898742676\n",
            "Batch: 3700, Loss: 2.328770160675049\n",
            "Batch: 3800, Loss: 2.0009918212890625\n",
            "Batch: 3900, Loss: 1.9537198543548584\n",
            "Batch: 4000, Loss: 2.046180248260498\n",
            "Batch: 4100, Loss: 1.8474862575531006\n",
            "Batch: 4200, Loss: 1.8676719665527344\n",
            "Batch: 4300, Loss: 2.2099015712738037\n",
            "Batch: 4400, Loss: 1.9901862144470215\n",
            "Batch: 4500, Loss: 1.8578640222549438\n",
            "Batch: 4600, Loss: 2.2396788597106934\n",
            "Batch: 4700, Loss: 2.3013668060302734\n",
            "Batch: 4800, Loss: 1.917922854423523\n",
            "Batch: 4900, Loss: 2.2099642753601074\n",
            "Batch: 5000, Loss: 1.5792959928512573\n",
            "Batch: 5100, Loss: 2.021512746810913\n",
            "Batch: 5200, Loss: 2.1643669605255127\n",
            "Batch: 5300, Loss: 2.057119607925415\n",
            "Batch: 5400, Loss: 2.1072096824645996\n",
            "Batch: 5500, Loss: 1.978270411491394\n",
            "Batch: 5600, Loss: 1.8530114889144897\n",
            "Batch: 5700, Loss: 2.0564048290252686\n",
            "Batch: 5800, Loss: 2.130523443222046\n",
            "Batch: 5900, Loss: 1.9590284824371338\n",
            "Batch: 6000, Loss: 1.949314832687378\n",
            "Batch: 6100, Loss: 2.335176706314087\n",
            "Batch: 6200, Loss: 2.322230100631714\n",
            "Batch: 6300, Loss: 1.9022119045257568\n",
            "Batch: 6400, Loss: 1.7695235013961792\n",
            "Batch: 6500, Loss: 2.165424108505249\n",
            "Batch: 6600, Loss: 1.8248428106307983\n",
            "Batch: 6700, Loss: 2.1634950637817383\n",
            "Batch: 6800, Loss: 2.2305290699005127\n",
            "Batch: 6900, Loss: 1.705986738204956\n",
            "Batch: 7000, Loss: 1.6994661092758179\n",
            "Batch: 7100, Loss: 1.777264952659607\n",
            "Batch: 7200, Loss: 1.8681491613388062\n",
            "Batch: 7300, Loss: 2.349064350128174\n",
            "Batch: 7400, Loss: 2.057331085205078\n",
            "Batch: 7500, Loss: 2.2185752391815186\n",
            "Batch: 7600, Loss: 2.2365660667419434\n",
            "Batch: 7700, Loss: 2.1359620094299316\n",
            "Batch: 7800, Loss: 1.525111436843872\n",
            "Batch: 7900, Loss: 2.0968823432922363\n",
            "Batch: 8000, Loss: 2.0820834636688232\n",
            "Batch: 8100, Loss: 1.7713732719421387\n",
            "Batch: 8200, Loss: 2.17757248878479\n",
            "Batch: 8300, Loss: 2.1002495288848877\n",
            "Batch: 8400, Loss: 1.7682180404663086\n",
            "Batch: 8500, Loss: 1.9719575643539429\n",
            "Batch: 8600, Loss: 1.5378069877624512\n",
            "Batch: 8700, Loss: 1.6064507961273193\n",
            "Batch: 8800, Loss: 2.2294089794158936\n",
            "Batch: 8900, Loss: 1.9033724069595337\n",
            "Batch: 9000, Loss: 1.686206340789795\n",
            "Batch: 9100, Loss: 1.7122663259506226\n",
            "Batch: 9200, Loss: 1.7759543657302856\n",
            "Batch: 9300, Loss: 1.7626760005950928\n",
            "Batch: 9400, Loss: 1.5539518594741821\n",
            "Batch: 9500, Loss: 1.931153416633606\n",
            "Batch: 9600, Loss: 1.5379058122634888\n",
            "Batch: 9700, Loss: 1.7746349573135376\n",
            "Batch: 9800, Loss: 1.7845423221588135\n",
            "Batch: 9900, Loss: 1.8607332706451416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scramble_n(cube, n):\n",
        "    for _ in range(n):\n",
        "        action = random.choice(movements)\n",
        "        cube._rotate_once(action)\n",
        "\n",
        "def attempt_solve(scramble_moves, max_moves):\n",
        "    cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "    goal_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "    scramble_n(cube, scramble_moves)\n",
        "    with torch.no_grad():\n",
        "      current_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "\n",
        "      for t in range(max_moves):\n",
        "        if t % 32 == 0:\n",
        "            mu_psi, sigma_psi = planner.forward(current_state.float(), goal_state.float())\n",
        "        z = mu_psi + sigma_psi * torch.randn_like(sigma_psi)\n",
        "\n",
        "        actor_dist, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "        action_index = torch.argmax(actor_dist, -1)\n",
        "\n",
        "        cube._rotate_once(movements[action_index])\n",
        "        current_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "        if cube.is_done():\n",
        "            return t + 1\n",
        "    return -1\n",
        "\n",
        "\n",
        "def test_batch(batch_size):\n",
        "\n",
        "    cubes = []\n",
        "    histories = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "      history = cube.scramble(1)\n",
        "\n",
        "      cubes.append(cube)\n",
        "      histories.append(history)\n",
        "\n",
        "    return cubes, histories\n",
        "\n",
        "def test_sample(batch_size, encoder, actor, planner):\n",
        "\n",
        "    goal_cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "    goal_state = get_cube_state(goal_cube)\n",
        "    goal_state = goal_state.unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n",
        "    goal_state = goal_state.view(goal_state.size(0), -1)\n",
        "\n",
        "    cubes, histories = test_batch(batch_size)\n",
        "\n",
        "    solved = [False] * batch_size\n",
        "    steps_taken = [0] * batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "      current_state = batch_cube_state(cubes).to(device)\n",
        "\n",
        "      mu_psi, sigma_psi = planner.forward(current_state.float(), goal_state.float())\n",
        "      z = torch.normal(mu_psi, sigma_psi)\n",
        "      actor_dist, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "      best_actions = torch.argmax(actor_dist, -1)\n",
        "\n",
        "      #evaluate\n",
        "      for i, action_index in enumerate(best_actions):\n",
        "        if not solved[i]:\n",
        "          cubes[i]._rotate_once(movements[action_index])\n",
        "          steps_taken[i] += 1\n",
        "          if cubes[i].is_done():\n",
        "            solved[i] = True\n",
        "\n",
        "\n",
        "    num_successful = sum(solved)\n",
        "    print(\"Number of successful solves: \", num_successful)\n",
        "\n"
      ],
      "metadata": {
        "id": "_XfezATofIWs"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in range(1, 11):\n",
        "  solve_count = 0\n",
        "  for i in range(1000):\n",
        "    moves = attempt_solve(d, 30)\n",
        "    if moves > 0:\n",
        "      solve_count += 1\n",
        "  print(d, \": \", solve_count)\n",
        "\n",
        "solve_count = 0\n",
        "for i in range(1000):\n",
        "  moves = attempt_solve(30, 80)\n",
        "  if moves > 0:\n",
        "    solve_count += 1\n",
        "print(solve_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MinRMH12gTqq",
        "outputId": "2a01f284-fcec-4ca9-cd7c-76c20d2096b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 :  455\n",
            "2 :  339\n",
            "3 :  191\n",
            "4 :  112\n",
            "5 :  58\n",
            "6 :  36\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}