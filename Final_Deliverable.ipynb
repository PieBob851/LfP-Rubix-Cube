{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcdoe1095pLo",
        "outputId": "ca79a6d4-e116-4154-e03e-c5c9c802983a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "Cloning into 'LfP-Rubix-Cube'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 41 (delta 16), reused 28 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (41/41), 25.55 KiB | 8.52 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "/LfP-Rubix-Cube\n"
          ]
        }
      ],
      "source": [
        "%cd ..\n",
        "!git clone https://github.com/PieBob851/LfP-Rubix-Cube.git\n",
        "%cd LfP-Rubix-Cube"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kZB5Lcq9uDc"
      },
      "source": [
        "# Imports & Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3Eu_3Jqu7n",
        "outputId": "ea5936af-a000-4dbe-ce3a-583c8c2e2cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from model.encoder import Encoder\n",
        "from model.planner import Planner\n",
        "from model.actor import Actor\n",
        "import torch\n",
        "from torch import nn, zeros\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from collections import deque\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfQFoZbGwbFH",
        "outputId": "ec6ecf0c-515d-4e12-b797-0b44f6e42603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting magiccube\n",
            "  Downloading magiccube-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from magiccube) (2.0.2)\n",
            "Downloading magiccube-1.0.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: magiccube\n",
            "Successfully installed magiccube-1.0.0\n",
            "Collecting kociemba\n",
            "  Downloading kociemba-1.2.1.tar.gz (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from kociemba) (1.17.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from kociemba) (1.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->kociemba) (2.22)\n",
            "Building wheels for collected packages: kociemba\n",
            "  Building wheel for kociemba (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kociemba: filename=kociemba-1.2.1-cp311-cp311-linux_x86_64.whl size=6800268 sha256=300572cd4c109311f64d13f8435c3984822c4162dca75ab9cb47e2579c5b8ee8\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/51/2f/f3b8548d55efe500bd3b8880b0c59e7c59d0bf765c5676c036\n",
            "Successfully built kociemba\n",
            "Installing collected packages: kociemba\n",
            "Successfully installed kociemba-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install magiccube\n",
        "!pip install kociemba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BzsAMibJsBvI"
      },
      "outputs": [],
      "source": [
        "import magiccube\n",
        "import copy\n",
        "from magiccube.cube_base import Color, Face\n",
        "from magiccube.cube_move import CubeMove\n",
        "from magiccube.cube_print import CubePrintStr\n",
        "from magiccube.solver.basic.basic_solver import BasicSolver\n",
        "import kociemba\n",
        "\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "def get_face_state(cube, face):\n",
        "    array_values = np.array([[color.value for color in row] for row in cube.get_face(face)])\n",
        "    tensor = torch.tensor(array_values.flatten(), dtype=torch.int64)\n",
        "    return torch.nn.functional.one_hot(tensor, num_classes=6).flatten()\n",
        "\n",
        "#state space\n",
        "def get_cube_state(cube):\n",
        "    return torch.stack([get_face_state(cube, Face.L), get_face_state(cube, Face.R), get_face_state(cube, Face.D), get_face_state(cube, Face.U), get_face_state(cube, Face.B), get_face_state(cube, Face.F)], dim=0)\n",
        "\n",
        "def batch_cube_state(cube_list):\n",
        "    current_states = []\n",
        "\n",
        "    for cube in cube_list:\n",
        "      current_states.append(get_cube_state(cube))\n",
        "\n",
        "    current_states = torch.stack(current_states)\n",
        "\n",
        "    return current_states.view(current_states.size(0), -1)\n",
        "\n",
        "def batch_apply_action(cube_list, action_list):\n",
        "  for i in range(len(cube_list)):\n",
        "    cube_list[i]._rotate_once(action_list[i])\n",
        "\n",
        "  return cube_list\n",
        "\n",
        "def get_kociemba_solve(cube):\n",
        "  in_format = \"YRGOBW\"\n",
        "  out_format = \"ULFRBD\"\n",
        "  ordered_format = \"URFDLB\"\n",
        "\n",
        "  translation_table_1 = str.maketrans(in_format, out_format)\n",
        "  translation_table_2 = str.maketrans(out_format, ordered_format)\n",
        "  printer = CubePrintStr(cube)\n",
        "  string = printer.print_cube().replace(\" \",\"\").replace(\"\\n\", \"\").translate(translation_table_1)\n",
        "  formatted = string[0:9] + string[15:18] + string[27:30] + string[39:42] \\\n",
        "              + string[12:15] + string[24:27] + string[36:39] + string[-9:] \\\n",
        "              + string[9:12] + string[21:24] + string[33:36] \\\n",
        "              + string[18:21] + string[30:33] + string[42:45]\n",
        "\n",
        "  return kociemba.solve(formatted)\n",
        "\n",
        "\n",
        "\n",
        "#action space\n",
        "movements = [\"L\", \"L'\", \"L2\", \"R\", \"R'\", \"R2\", \"D\", \"D'\", \"D2\", \"U\", \"U'\", \"U2\", \"B\", \"B'\", \"B2\", \"F\", \"F'\", \"F2\"]\n",
        "reversals = [\"L'\", \"L\", \"L2\", \"R'\", \"R\", \"R2\", \"D'\", \"D\", \"D2\", \"U'\", \"U\", \"U2\", \"B'\", \"B\", \"B2\", \"F'\", \"F\", \"F2\"]\n",
        "reverse_index = {0: 1, 1: 0, 2: 2, 3: 4, 4: 3, 5: 5, 6: 7, 7: 6, 8: 8, 9: 10, 10: 9, 11: 11, 12: 13, 13: 12, 14: 14, 15: 16, 16:15, 17:17}\n",
        "move_dict =  {\"L\": 0, \"L'\": 1, \"L2\": 2, \"R\": 3, \"R'\": 4, \"R2\": 5, \"D\": 6, \"D'\": 7, \"D2\": 8, \"U\": 9, \"U'\": 10, \"U2\": 11, \"B\": 12, \"B'\": 13, \"B2\": 14, \"F\": 15, \"F'\": 16, \"F2\": 17}\n",
        "reversals = [CubeMove.create(move_str) for move_str in reversals]\n",
        "movements = [CubeMove.create(move_str) for move_str in movements]\n",
        "\n",
        "# cube._rotate_once(movements[8])\n",
        "# solver = BasicSolver(cube)\n",
        "# cube_copy = copy.deepcopy(cube)\n",
        "# solver.solve()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0gooVAu97L4"
      },
      "source": [
        "# Data Collection\n",
        "\n",
        "Different ways to collect data (only one should be used)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a317An1e-8Tw"
      },
      "source": [
        "Random move selection - at every timestep, a random move is chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "raWpW0b_vkBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7002d0c8-98e1-4e2a-e6e9-6e56c8d38e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n",
            "Sample: 10000\n",
            "Sample: 20000\n",
            "Sample: 30000\n",
            "Sample: 40000\n",
            "Sample: 50000\n",
            "Sample: 60000\n",
            "Sample: 70000\n",
            "Sample: 80000\n",
            "Sample: 90000\n",
            "Sample: 100000\n",
            "Sample: 110000\n",
            "Sample: 120000\n",
            "Sample: 130000\n",
            "Sample: 140000\n",
            "Sample: 150000\n",
            "Sample: 160000\n",
            "Sample: 170000\n",
            "Sample: 180000\n",
            "Sample: 190000\n",
            "Sample: 200000\n",
            "Sample: 210000\n",
            "Sample: 220000\n",
            "Sample: 230000\n",
            "Sample: 240000\n",
            "Sample: 250000\n",
            "Sample: 260000\n",
            "Sample: 270000\n",
            "Sample: 280000\n",
            "Sample: 290000\n",
            "Sample: 300000\n",
            "Sample: 310000\n",
            "Sample: 320000\n",
            "Sample: 330000\n",
            "Sample: 340000\n",
            "Sample: 350000\n",
            "Sample: 360000\n",
            "Sample: 370000\n",
            "Sample: 380000\n",
            "Sample: 390000\n",
            "Sample: 400000\n",
            "Sample: 410000\n",
            "Sample: 420000\n",
            "Sample: 430000\n",
            "Sample: 440000\n",
            "Sample: 450000\n",
            "Sample: 460000\n",
            "Sample: 470000\n",
            "Sample: 480000\n",
            "Sample: 490000\n",
            "Sample: 500000\n",
            "Sample: 510000\n",
            "Sample: 520000\n",
            "Sample: 530000\n",
            "Sample: 540000\n",
            "Sample: 550000\n",
            "Sample: 560000\n",
            "Sample: 570000\n",
            "Sample: 580000\n",
            "Sample: 590000\n",
            "Sample: 600000\n",
            "Sample: 610000\n",
            "Sample: 620000\n",
            "Sample: 630000\n",
            "Sample: 640000\n",
            "Sample: 650000\n",
            "Sample: 660000\n",
            "Sample: 670000\n",
            "Sample: 680000\n",
            "Sample: 690000\n",
            "Sample: 700000\n",
            "Sample: 710000\n",
            "Sample: 720000\n",
            "Sample: 730000\n",
            "Sample: 740000\n",
            "Sample: 750000\n",
            "Sample: 760000\n",
            "Sample: 770000\n",
            "Sample: 780000\n",
            "Sample: 790000\n",
            "Sample: 800000\n",
            "Sample: 810000\n",
            "Sample: 820000\n",
            "Sample: 830000\n",
            "Sample: 840000\n",
            "Sample: 850000\n",
            "Sample: 860000\n",
            "Sample: 870000\n",
            "Sample: 880000\n",
            "Sample: 890000\n",
            "Sample: 900000\n",
            "Sample: 910000\n",
            "Sample: 920000\n",
            "Sample: 930000\n",
            "Sample: 940000\n",
            "Sample: 950000\n",
            "Sample: 960000\n",
            "Sample: 970000\n",
            "Sample: 980000\n",
            "Sample: 990000\n"
          ]
        }
      ],
      "source": [
        "# random move at every step for dataset creation\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 1000000\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "for i in range(num_samples):\n",
        "  if i % 10000 == 0:\n",
        "    print(f\"Sample: {i}\")\n",
        "  state = get_cube_state(cube).flatten()\n",
        "  data_raw[i, :state_dim] = state\n",
        "\n",
        "  action = random.choice(range(action_dim))\n",
        "  data_raw[i, state_dim + action] = 1\n",
        "\n",
        "  cube._rotate_once(movements[action])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2ZakNFh_DTZ"
      },
      "source": [
        "Random move selection with reversing - starts with a solved cube, then advances move_depth steps forward with random move selection. After this, it reverses those moves (so the cube is once again solved)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "Xj43AWNf5Qx7",
        "outputId": "b27de8a2-16c8-4f4d-e527-4777d7c9723e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n",
            "Sample: 10000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-73a5a2a61ca9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Sample: {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cube_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mdata_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-801b517fe7de>\u001b[0m in \u001b[0;36mget_cube_state\u001b[0;34m(cube)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#state space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_cube_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_face_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_face_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_face_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_face_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_face_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_face_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbatch_cube_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcube_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-801b517fe7de>\u001b[0m in \u001b[0;36mget_face_state\u001b[0;34m(cube, face)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0marray_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#state space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# forward set number of moves, before reversing\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100000\n",
        "move_depth = 16  # Number of forward moves before reversing\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3, \"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "i = 0\n",
        "while i < num_samples:\n",
        "  forward_actions = []\n",
        "  for _ in range(move_depth):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    action = random.choice(range(action_dim))\n",
        "    data_raw[i, state_dim + action] = 1\n",
        "    cube._rotate_once(movements[action])\n",
        "    forward_actions.append(action)\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break\n",
        "\n",
        "  for action in reversed(forward_actions):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    reverse_action = reverse_index[action]\n",
        "    data_raw[i, state_dim + reverse_action] = 1\n",
        "    cube._rotate_once(movements[reverse_action])\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using MacgicCube's scramble() and solve() functions - generates a random state, then solves the cube forward from that state."
      ],
      "metadata": {
        "id": "vtR_fXT5vdnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kociemba\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 1000000\n",
        "move_depth = 10  # Number of forward moves before reversing\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "solved_cube = magiccube.Cube(3, \"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "# print(cube)\n",
        "in_str =  \"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\"\n",
        "\n",
        "i = 0\n",
        "while i < num_samples:\n",
        "  cube = copy.deepcopy(solved_cube)\n",
        "  action_cube = copy.deepcopy(cube)\n",
        "  scramble_history = action_cube.scramble(move_depth)\n",
        "  solve_history = get_kociemba_solve(action_cube).split()\n",
        "  if len(solve_history) > 22: #would be longer than the encoder dimension\n",
        "    pass\n",
        "  else:\n",
        "    total_dim = len(scramble_history) + len(solve_history)\n",
        "    padding_needed = 32 - total_dim\n",
        "    for j in range(move_depth):\n",
        "      if i % 10000 == 0:\n",
        "          print(f\"Sample: {i}\")\n",
        "      state = get_cube_state(cube).flatten()\n",
        "      data_raw[i, :state_dim] = state\n",
        "\n",
        "      action = move_dict[str(scramble_history[j])]\n",
        "      data_raw[i, state_dim + action] = 1\n",
        "      cube._rotate_once(movements[action])\n",
        "      i += 1\n",
        "\n",
        "      if i >= num_samples:\n",
        "        break\n",
        "    for action in solve_history:\n",
        "      if i % 10000 == 0:\n",
        "          print(f\"Sample: {i}\")\n",
        "      state = get_cube_state(cube).flatten()\n",
        "      data_raw[i, :state_dim] = state\n",
        "\n",
        "      raw_action = move_dict[str(action)]\n",
        "      data_raw[i, state_dim + raw_action] = 1\n",
        "      move = CubeMove.create(action)\n",
        "      cube._rotate_once(move)\n",
        "\n",
        "      i += 1\n",
        "      if i >= num_samples:\n",
        "        break\n",
        "\n",
        "    i += padding_needed\n",
        "    # if cube.is_done():\n",
        "    #  print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJG5b0Pvvboh",
        "outputId": "d44b3baa-d9fd-40a0-e2e2-f5c903afc929"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 0\n",
            "Sample: 10000\n",
            "Sample: 20000\n",
            "Sample: 30000\n",
            "Sample: 40000\n",
            "Sample: 50000\n",
            "Sample: 60000\n",
            "Sample: 70000\n",
            "Sample: 80000\n",
            "Sample: 90000\n",
            "Sample: 100000\n",
            "Sample: 110000\n",
            "Sample: 120000\n",
            "Sample: 140000\n",
            "Sample: 160000\n",
            "Sample: 170000\n",
            "Sample: 180000\n",
            "Sample: 190000\n",
            "Sample: 200000\n",
            "Sample: 220000\n",
            "Sample: 240000\n",
            "Sample: 250000\n",
            "Sample: 260000\n",
            "Sample: 280000\n",
            "Sample: 290000\n",
            "Sample: 300000\n",
            "Sample: 310000\n",
            "Sample: 320000\n",
            "Sample: 330000\n",
            "Sample: 340000\n",
            "Sample: 350000\n",
            "Sample: 360000\n",
            "Sample: 370000\n",
            "Sample: 380000\n",
            "Sample: 390000\n",
            "Sample: 400000\n",
            "Sample: 410000\n",
            "Sample: 420000\n",
            "Sample: 430000\n",
            "Sample: 440000\n",
            "Sample: 460000\n",
            "Sample: 470000\n",
            "Sample: 480000\n",
            "Sample: 490000\n",
            "Sample: 500000\n",
            "Sample: 510000\n",
            "Sample: 520000\n",
            "Sample: 530000\n",
            "Sample: 540000\n",
            "Sample: 550000\n",
            "Sample: 560000\n",
            "Sample: 580000\n",
            "Sample: 590000\n",
            "Sample: 600000\n",
            "Sample: 610000\n",
            "Sample: 620000\n",
            "Sample: 640000\n",
            "Sample: 650000\n",
            "Sample: 660000\n",
            "Sample: 670000\n",
            "Sample: 680000\n",
            "Sample: 690000\n",
            "Sample: 700000\n",
            "Sample: 720000\n",
            "Sample: 730000\n",
            "Sample: 740000\n",
            "Sample: 750000\n",
            "Sample: 760000\n",
            "Sample: 770000\n",
            "Sample: 780000\n",
            "Sample: 790000\n",
            "Sample: 800000\n",
            "Sample: 810000\n",
            "Sample: 820000\n",
            "Sample: 830000\n",
            "Sample: 840000\n",
            "Sample: 860000\n",
            "Sample: 870000\n",
            "Sample: 880000\n",
            "Sample: 890000\n",
            "Sample: 900000\n",
            "Sample: 910000\n",
            "Sample: 920000\n",
            "Sample: 930000\n",
            "Sample: 940000\n",
            "Sample: 950000\n",
            "Sample: 960000\n",
            "Sample: 970000\n",
            "Sample: 980000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pdcQeEuiJld9"
      },
      "outputs": [],
      "source": [
        "#Getting Data\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, data):\n",
        "        self.data_list = data\n",
        "\n",
        "    def sample_batch(self, batch_size):\n",
        "        start_indices = np.random.randint(0, len(self.data_list) - 32, size=batch_size)[:, np.newaxis]\n",
        "        indices = start_indices + np.arange(32)[np.newaxis, :]\n",
        "\n",
        "        sample = self.data_list[indices]\n",
        "        return sample\n",
        "\n",
        "data = Dataset(data_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dnqS0mJkMbHd"
      },
      "outputs": [],
      "source": [
        "latent_dim = 128\n",
        "\n",
        "encoder = Encoder(state_dim + action_dim, layer_size=256, latent_dim=latent_dim).to(device)\n",
        "planner = Planner(state_dim, state_dim, layer_size=1024, latent_dim=latent_dim).to(device)\n",
        "actor = Actor(state_dim, action_dim, state_dim, layer_size=1024, latent_dim=latent_dim).to(device)\n",
        "\n",
        "encoder_optimizer = Adam(encoder.parameters(), lr=5e-5)\n",
        "planner_optimizer = Adam(planner.parameters(), lr=5e-5)\n",
        "actor_optimizer = Adam(actor.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgt8MyeA-ElT"
      },
      "source": [
        "# Training and Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "V2A3_IwZB1js"
      },
      "outputs": [],
      "source": [
        "import torch.distributions as dist\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_sample(batch_size, beta, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer, data):\n",
        "    sample = data.sample_batch(batch_size).to(device)\n",
        "    current_state = sample[:, 0, :-18]\n",
        "    current_action = sample[:, 0, -18:]\n",
        "    goal_state = sample[:, -1, :-18]\n",
        "    goal_action = sample[:, -1, -18:]\n",
        "\n",
        "    z, mu_phi, sigma_phi = encoder.forward(sample)\n",
        "    mu_psi, sigma_psi = planner.forward(current_state, goal_state)\n",
        "\n",
        "    phi_gaussian = dist.Normal(mu_phi, sigma_phi)\n",
        "\n",
        "    psi_gaussian = dist.Normal(mu_psi, sigma_psi)\n",
        "\n",
        "    KL_loss = torch.sum(dist.kl.kl_divergence(phi_gaussian, psi_gaussian))\n",
        "\n",
        "    policy_action, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "    action_loss = F.cross_entropy(policy_action.squeeze(1), current_action)\n",
        "\n",
        "    loss = beta * KL_loss + action_loss\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    planner_optimizer.zero_grad()\n",
        "    actor_optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    planner_optimizer.step()\n",
        "    actor_optimizer.step()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRQTwsBKUjee",
        "outputId": "5c17fb06-9a41-4405-f2a6-2321cf038dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0, Loss: 11.282220840454102\n",
            "Batch: 100, Loss: 1.7637872695922852\n",
            "Batch: 200, Loss: 1.7902941703796387\n",
            "Batch: 300, Loss: 1.2967591285705566\n",
            "Batch: 400, Loss: 1.3948371410369873\n",
            "Batch: 500, Loss: 1.14382004737854\n",
            "Batch: 600, Loss: 1.9683741331100464\n",
            "Batch: 700, Loss: 1.2726386785507202\n",
            "Batch: 800, Loss: 2.018338441848755\n",
            "Batch: 900, Loss: 1.1932566165924072\n",
            "Batch: 1000, Loss: 1.7672487497329712\n",
            "Batch: 1100, Loss: 1.3155299425125122\n",
            "Batch: 1200, Loss: 1.3059524297714233\n",
            "Batch: 1300, Loss: 1.265215516090393\n",
            "Batch: 1400, Loss: 1.3285616636276245\n",
            "Batch: 1500, Loss: 1.4579813480377197\n",
            "Batch: 1600, Loss: 1.439035415649414\n",
            "Batch: 1700, Loss: 1.5441960096359253\n",
            "Batch: 1800, Loss: 1.1578792333602905\n",
            "Batch: 1900, Loss: 1.5820704698562622\n",
            "Batch: 2000, Loss: 1.3851162195205688\n",
            "Batch: 2100, Loss: 1.983910322189331\n",
            "Batch: 2200, Loss: 1.6077473163604736\n",
            "Batch: 2300, Loss: 1.1440634727478027\n",
            "Batch: 2400, Loss: 1.5350325107574463\n",
            "Batch: 2500, Loss: 1.5772147178649902\n",
            "Batch: 2600, Loss: 1.248757004737854\n",
            "Batch: 2700, Loss: 1.3557629585266113\n",
            "Batch: 2800, Loss: 1.544921875\n",
            "Batch: 2900, Loss: 0.8668404221534729\n",
            "Batch: 3000, Loss: 1.844838261604309\n",
            "Batch: 3100, Loss: 1.2713098526000977\n",
            "Batch: 3200, Loss: 1.1586655378341675\n",
            "Batch: 3300, Loss: 1.713437557220459\n",
            "Batch: 3400, Loss: 1.545875072479248\n",
            "Batch: 3500, Loss: 1.3173362016677856\n",
            "Batch: 3600, Loss: 1.3519278764724731\n",
            "Batch: 3700, Loss: 1.139418125152588\n",
            "Batch: 3800, Loss: 1.364709734916687\n",
            "Batch: 3900, Loss: 1.2606329917907715\n",
            "Batch: 4000, Loss: 1.3004809617996216\n",
            "Batch: 4100, Loss: 1.5509107112884521\n",
            "Batch: 4200, Loss: 1.2272175550460815\n",
            "Batch: 4300, Loss: 1.138702630996704\n",
            "Batch: 4400, Loss: 1.250153660774231\n",
            "Batch: 4500, Loss: 1.2807209491729736\n",
            "Batch: 4600, Loss: 1.3873116970062256\n",
            "Batch: 4700, Loss: 0.8997880816459656\n",
            "Batch: 4800, Loss: 1.5446518659591675\n",
            "Batch: 4900, Loss: 1.5601913928985596\n",
            "Batch: 5000, Loss: 1.1700183153152466\n",
            "Batch: 5100, Loss: 1.1280677318572998\n",
            "Batch: 5200, Loss: 1.6239964962005615\n",
            "Batch: 5300, Loss: 1.577399492263794\n",
            "Batch: 5400, Loss: 1.3976644277572632\n",
            "Batch: 5500, Loss: 1.2898305654525757\n",
            "Batch: 5600, Loss: 1.1876492500305176\n",
            "Batch: 5700, Loss: 1.159682273864746\n",
            "Batch: 5800, Loss: 1.1894207000732422\n",
            "Batch: 5900, Loss: 1.2236840724945068\n",
            "Batch: 6000, Loss: 1.1931301355361938\n",
            "Batch: 6100, Loss: 1.3561075925827026\n",
            "Batch: 6200, Loss: 1.6869807243347168\n",
            "Batch: 6300, Loss: 1.6976501941680908\n",
            "Batch: 6400, Loss: 1.4808682203292847\n",
            "Batch: 6500, Loss: 1.381615400314331\n",
            "Batch: 6600, Loss: 1.0069382190704346\n",
            "Batch: 6700, Loss: 1.4966580867767334\n",
            "Batch: 6800, Loss: 1.585702657699585\n",
            "Batch: 6900, Loss: 1.0899527072906494\n",
            "Batch: 7000, Loss: 1.2734382152557373\n",
            "Batch: 7100, Loss: 1.3120622634887695\n",
            "Batch: 7200, Loss: 1.4178253412246704\n",
            "Batch: 7300, Loss: 0.9843326807022095\n",
            "Batch: 7400, Loss: 1.7349375486373901\n",
            "Batch: 7500, Loss: 1.0966349840164185\n",
            "Batch: 7600, Loss: 0.8842390179634094\n",
            "Batch: 7700, Loss: 0.8382934927940369\n",
            "Batch: 7800, Loss: 1.30934739112854\n",
            "Batch: 7900, Loss: 1.2766133546829224\n",
            "Batch: 8000, Loss: 1.324007511138916\n",
            "Batch: 8100, Loss: 1.1516870260238647\n",
            "Batch: 8200, Loss: 1.3784061670303345\n",
            "Batch: 8300, Loss: 1.5003314018249512\n",
            "Batch: 8400, Loss: 1.312370777130127\n",
            "Batch: 8500, Loss: 1.3441241979599\n",
            "Batch: 8600, Loss: 1.2727066278457642\n",
            "Batch: 8700, Loss: 1.1294782161712646\n",
            "Batch: 8800, Loss: 1.047163724899292\n",
            "Batch: 8900, Loss: 1.3302096128463745\n",
            "Batch: 9000, Loss: 1.5823041200637817\n",
            "Batch: 9100, Loss: 1.1711759567260742\n",
            "Batch: 9200, Loss: 1.2344659566879272\n",
            "Batch: 9300, Loss: 1.3556187152862549\n",
            "Batch: 9400, Loss: 1.32676362991333\n",
            "Batch: 9500, Loss: 1.3968058824539185\n",
            "Batch: 9600, Loss: 1.635001540184021\n",
            "Batch: 9700, Loss: 1.1205836534500122\n",
            "Batch: 9800, Loss: 1.4016691446304321\n",
            "Batch: 9900, Loss: 0.993595540523529\n"
          ]
        }
      ],
      "source": [
        "loss_list = []\n",
        "batch_list = []\n",
        "for batch in range(10000):\n",
        "    loss = train_sample(32, .9, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer, data)\n",
        "    if batch % 100 == 0:\n",
        "        print(f\"Batch: {batch}, Loss: {loss}\")\n",
        "        # loss_list.append(loss.cpu())\n",
        "        # batch_list.append(batch.cpu())\n",
        "\n",
        "# with open('Kociembas_basic.txt', 'w') as f:\n",
        "#     for item in loss_list:\n",
        "#         f.write(f\"{item}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(batch_list, loss_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "xnE-sqDV5rZS",
        "outputId": "46f47393-9d51-4878-990d-ae18db6db789"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'cpu'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2e3a6f3389c2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'cpu'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_XfezATofIWs"
      },
      "outputs": [],
      "source": [
        "def scramble_n(cube, n):\n",
        "    for _ in range(n):\n",
        "        action = random.choice(movements)\n",
        "        cube._rotate_once(action)\n",
        "\n",
        "def attempt_solve(scramble_moves, max_moves):\n",
        "    cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "    goal_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "    scramble_n(cube, scramble_moves)\n",
        "    with torch.no_grad():\n",
        "      current_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "\n",
        "      for t in range(max_moves):\n",
        "        if t % 32 == 0:\n",
        "            mu_psi, sigma_psi = planner.forward(current_state.float(), goal_state.float())\n",
        "        z = mu_psi + sigma_psi * torch.randn_like(sigma_psi)\n",
        "\n",
        "        actor_dist, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "        action_index = torch.argmax(actor_dist, -1)\n",
        "\n",
        "        cube._rotate_once(movements[action_index])\n",
        "        current_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "        if cube.is_done():\n",
        "            return t + 1\n",
        "    return -1\n",
        "\n",
        "\n",
        "def test_batch(batch_size):\n",
        "\n",
        "    cubes = []\n",
        "    histories = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "      history = cube.scramble(1)\n",
        "\n",
        "      cubes.append(cube)\n",
        "      histories.append(history)\n",
        "\n",
        "    return cubes, histories\n",
        "\n",
        "def test_sample(batch_size, encoder, actor, planner):\n",
        "\n",
        "    goal_cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "    goal_state = get_cube_state(goal_cube)\n",
        "    goal_state = goal_state.unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n",
        "    goal_state = goal_state.view(goal_state.size(0), -1)\n",
        "\n",
        "    cubes, histories = test_batch(batch_size)\n",
        "\n",
        "    solved = [False] * batch_size\n",
        "    steps_taken = [0] * batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "      current_state = batch_cube_state(cubes).to(device)\n",
        "\n",
        "      mu_psi, sigma_psi = planner.forward(current_state.float(), goal_state.float())\n",
        "      z = torch.normal(mu_psi, sigma_psi)\n",
        "      actor_dist, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "      best_actions = torch.argmax(actor_dist, -1)\n",
        "\n",
        "      #evaluate\n",
        "      for i, action_index in enumerate(best_actions):\n",
        "        if not solved[i]:\n",
        "          cubes[i]._rotate_once(movements[action_index])\n",
        "          steps_taken[i] += 1\n",
        "          if cubes[i].is_done():\n",
        "            solved[i] = True\n",
        "\n",
        "\n",
        "    num_successful = sum(solved)\n",
        "    print(\"Number of successful solves: \", num_successful)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MinRMH12gTqq",
        "outputId": "62952434-755c-42b0-92d0-fcc1bf146692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 :  998\n",
            "2 :  915\n",
            "3 :  746\n",
            "4 :  513\n",
            "5 :  344\n",
            "6 :  217\n",
            "7 :  127\n",
            "8 :  79\n",
            "9 :  45\n",
            "10 :  35\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "for d in range(1, 11):\n",
        "  solve_count = 0\n",
        "  for i in range(1000):\n",
        "    moves = attempt_solve(d, 30)\n",
        "    if moves > 0:\n",
        "      solve_count += 1\n",
        "  print(d, \": \", solve_count)\n",
        "\n",
        "solve_count = 0\n",
        "for i in range(1000):\n",
        "  moves = attempt_solve(30, 80)\n",
        "  if moves > 0:\n",
        "    solve_count += 1\n",
        "print(solve_count)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}