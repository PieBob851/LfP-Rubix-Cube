{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcdoe1095pLo",
        "outputId": "91becad2-0ed3-4b93-c9b6-7a41654ab23d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/\n",
            "Cloning into 'LfP-Rubix-Cube'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 35 (delta 14), reused 23 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (35/35), 20.32 KiB | 10.16 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "/LfP-Rubix-Cube\n"
          ]
        }
      ],
      "source": [
        "%cd ..\n",
        "!git clone https://github.com/PieBob851/LfP-Rubix-Cube.git\n",
        "%cd LfP-Rubix-Cube"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kZB5Lcq9uDc"
      },
      "source": [
        "# Imports & Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3Eu_3Jqu7n",
        "outputId": "28f077ef-a7a1-415d-d932-10b153048825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from model.encoder import Encoder\n",
        "from model.planner import Planner\n",
        "from model.actor import Actor\n",
        "import torch\n",
        "from torch import nn, zeros\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from collections import deque\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfQFoZbGwbFH",
        "outputId": "0a546c5d-2a83-4bc2-e963-d801888e74c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting magiccube\n",
            "  Downloading magiccube-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from magiccube) (2.0.2)\n",
            "Downloading magiccube-1.0.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: magiccube\n",
            "Successfully installed magiccube-1.0.0\n",
            "Collecting kociemba\n",
            "  Downloading kociemba-1.2.1.tar.gz (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from kociemba) (1.17.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from kociemba) (1.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->kociemba) (2.22)\n",
            "Building wheels for collected packages: kociemba\n",
            "  Building wheel for kociemba (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kociemba: filename=kociemba-1.2.1-cp311-cp311-linux_x86_64.whl size=6800269 sha256=9580a2bd5572b01358d59e8c60dd083882fbca6d524c9b8dbd3cad478821d8b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/51/2f/f3b8548d55efe500bd3b8880b0c59e7c59d0bf765c5676c036\n",
            "Successfully built kociemba\n",
            "Installing collected packages: kociemba\n",
            "Successfully installed kociemba-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install magiccube\n",
        "!pip install kociemba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BzsAMibJsBvI"
      },
      "outputs": [],
      "source": [
        "import magiccube\n",
        "import copy\n",
        "from magiccube.cube_base import Color, Face\n",
        "from magiccube.cube_move import CubeMove\n",
        "from magiccube.cube_print import CubePrintStr\n",
        "from magiccube.solver.basic.basic_solver import BasicSolver\n",
        "import kociemba\n",
        "\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "def get_face_state(cube, face):\n",
        "    array_values = np.array([[color.value for color in row] for row in cube.get_face(face)])\n",
        "    tensor = torch.tensor(array_values.flatten(), dtype=torch.int64)\n",
        "    return torch.nn.functional.one_hot(tensor, num_classes=6).flatten()\n",
        "\n",
        "#state space\n",
        "def get_cube_state(cube):\n",
        "    return torch.stack([get_face_state(cube, Face.L), get_face_state(cube, Face.R), get_face_state(cube, Face.D), get_face_state(cube, Face.U), get_face_state(cube, Face.B), get_face_state(cube, Face.F)], dim=0)\n",
        "\n",
        "def batch_cube_state(cube_list):\n",
        "    current_states = []\n",
        "\n",
        "    for cube in cube_list:\n",
        "      current_states.append(get_cube_state(cube))\n",
        "\n",
        "    current_states = torch.stack(current_states)\n",
        "\n",
        "    return current_states.view(current_states.size(0), -1)\n",
        "\n",
        "def batch_apply_action(cube_list, action_list):\n",
        "  for i in range(len(cube_list)):\n",
        "    cube_list[i]._rotate_once(action_list[i])\n",
        "\n",
        "  return cube_list\n",
        "\n",
        "def get_kociemba_solve(cube):\n",
        "  in_format = \"YRGOBW\"\n",
        "  out_format = \"ULFRBD\"\n",
        "  ordered_format = \"URFDLB\"\n",
        "\n",
        "  translation_table_1 = str.maketrans(in_format, out_format)\n",
        "  translation_table_2 = str.maketrans(out_format, ordered_format)\n",
        "  printer = CubePrintStr(cube)\n",
        "  string = printer.print_cube().replace(\" \",\"\").replace(\"\\n\", \"\").translate(translation_table_1)\n",
        "  formatted = string[0:9] + string[15:18] + string[27:30] + string[39:42] \\\n",
        "              + string[12:15] + string[24:27] + string[36:39] + string[-9:] \\\n",
        "              + string[9:12] + string[21:24] + string[33:36] \\\n",
        "              + string[18:21] + string[30:33] + string[42:45]\n",
        "\n",
        "  return kociemba.solve(formatted)\n",
        "\n",
        "\n",
        "\n",
        "#action space\n",
        "movements = [\"L\", \"L'\", \"L2\", \"R\", \"R'\", \"R2\", \"D\", \"D'\", \"D2\", \"U\", \"U'\", \"U2\", \"B\", \"B'\", \"B2\", \"F\", \"F'\", \"F2\"]\n",
        "reversals = [\"L'\", \"L\", \"L2\", \"R'\", \"R\", \"R2\", \"D'\", \"D\", \"D2\", \"U'\", \"U\", \"U2\", \"B'\", \"B\", \"B2\", \"F'\", \"F\", \"F2\"]\n",
        "reverse_index = {0: 1, 1: 0, 2: 2, 3: 4, 4: 3, 5: 5, 6: 7, 7: 6, 8: 8, 9: 10, 10: 9, 11: 11, 12: 13, 13: 12, 14: 14, 15: 16, 16:15, 17:17}\n",
        "move_dict =  {\"L\": 0, \"L'\": 1, \"L2\": 2, \"R\": 3, \"R'\": 4, \"R2\": 5, \"D\": 6, \"D'\": 7, \"D2\": 8, \"U\": 9, \"U'\": 10, \"U2\": 11, \"B\": 12, \"B'\": 13, \"B2\": 14, \"F\": 15, \"F'\": 16, \"F2\": 17}\n",
        "reversals = [CubeMove.create(move_str) for move_str in reversals]\n",
        "movements = [CubeMove.create(move_str) for move_str in movements]\n",
        "\n",
        "# cube._rotate_once(movements[8])\n",
        "# solver = BasicSolver(cube)\n",
        "# cube_copy = copy.deepcopy(cube)\n",
        "# solver.solve()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0gooVAu97L4"
      },
      "source": [
        "# Data Collection\n",
        "\n",
        "Different ways to collect data (only one should be used)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a317An1e-8Tw"
      },
      "source": [
        "Random move selection - at every timestep, a random move is chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "raWpW0b_vkBW",
        "outputId": "eb11bc5e-35d4-43db-afc9-32fadb8b6536"
      },
      "outputs": [],
      "source": [
        "# random move at every step for dataset creation\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100000\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "for i in range(num_samples):\n",
        "  if i % 10000 == 0:\n",
        "    print(f\"Sample: {i}\")\n",
        "  state = get_cube_state(cube).flatten()\n",
        "  data_raw[i, :state_dim] = state\n",
        "\n",
        "  action = random.choice(range(action_dim))\n",
        "  data_raw[i, state_dim + action] = 1\n",
        "\n",
        "  cube._rotate_once(movements[action])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2ZakNFh_DTZ"
      },
      "source": [
        "Random move selection with reversing - starts with a solved cube, then advances move_depth steps forward with random move selection. After this, it reverses those moves (so the cube is once again solved)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj43AWNf5Qx7",
        "outputId": "1511ddcb-4972-4845-a35d-5ab90b2b3302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample: 0\n",
            "Sample: 10000\n",
            "Sample: 20000\n",
            "Sample: 30000\n",
            "Sample: 40000\n",
            "Sample: 50000\n",
            "Sample: 60000\n",
            "Sample: 70000\n",
            "Sample: 80000\n",
            "Sample: 90000\n"
          ]
        }
      ],
      "source": [
        "# forward set number of moves, before reversing\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100000\n",
        "move_depth = 16  # Number of forward moves before reversing\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "cube = magiccube.Cube(3, \"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "\n",
        "i = 0\n",
        "while i < num_samples:\n",
        "  forward_actions = []\n",
        "  for _ in range(move_depth):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    action = random.choice(range(action_dim))\n",
        "    data_raw[i, state_dim + action] = 1\n",
        "    cube._rotate_once(movements[action])\n",
        "    forward_actions.append(action)\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break\n",
        "\n",
        "  for action in reversed(forward_actions):\n",
        "    if i % 10000 == 0:\n",
        "        print(f\"Sample: {i}\")\n",
        "    state = get_cube_state(cube).flatten()\n",
        "    data_raw[i, :state_dim] = state\n",
        "\n",
        "    reverse_action = reverse_index[action]\n",
        "    data_raw[i, state_dim + reverse_action] = 1\n",
        "    cube._rotate_once(movements[reverse_action])\n",
        "\n",
        "    i += 1\n",
        "    if i >= num_samples:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtR_fXT5vdnM"
      },
      "source": [
        "Using MacgicCube's scramble() and solve() functions - generates a random state, then solves the cube forward from that state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJG5b0Pvvboh",
        "outputId": "3ba76158-02f0-474f-e5cc-363c07596892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample: 0\n",
            "Sample: 10000\n",
            "Sample: 20000\n",
            "Sample: 30000\n",
            "Sample: 40000\n",
            "Sample: 50000\n",
            "Sample: 60000\n",
            "Sample: 70000\n",
            "Sample: 80000\n"
          ]
        }
      ],
      "source": [
        "import kociemba\n",
        "action_dim = 18\n",
        "state_dim = 54 * 6\n",
        "num_samples = 100000\n",
        "move_depth = 10  # Number of forward moves before reversing\n",
        "\n",
        "data_raw = torch.zeros((num_samples, action_dim + state_dim))\n",
        "solved_cube = magiccube.Cube(3, \"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "# print(cube)\n",
        "in_str =  \"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\"\n",
        "\n",
        "i = 0\n",
        "while i < num_samples:\n",
        "  cube = copy.deepcopy(solved_cube)\n",
        "  action_cube = copy.deepcopy(cube)\n",
        "  scramble_history = action_cube.scramble(move_depth)\n",
        "  solve_history = get_kociemba_solve(action_cube).split()\n",
        "  if len(solve_history) > 22: #would be longer than the encoder dimension\n",
        "    pass\n",
        "  else:\n",
        "    total_dim = len(scramble_history) + len(solve_history)\n",
        "    padding_needed = 32 - total_dim\n",
        "    for j in range(move_depth):\n",
        "      if i % 10000 == 0:\n",
        "          print(f\"Sample: {i}\")\n",
        "      state = get_cube_state(cube).flatten()\n",
        "      data_raw[i, :state_dim] = state\n",
        "\n",
        "      action = move_dict[str(scramble_history[j])]\n",
        "      data_raw[i, state_dim + action] = 1\n",
        "      cube._rotate_once(movements[action])\n",
        "      i += 1\n",
        "\n",
        "      if i >= num_samples:\n",
        "        break\n",
        "    for action in solve_history:\n",
        "      if i % 10000 == 0:\n",
        "          print(f\"Sample: {i}\")\n",
        "      state = get_cube_state(cube).flatten()\n",
        "      data_raw[i, :state_dim] = state\n",
        "\n",
        "      raw_action = move_dict[str(action)]\n",
        "      data_raw[i, state_dim + raw_action] = 1\n",
        "      move = CubeMove.create(action)\n",
        "      cube._rotate_once(move)\n",
        "\n",
        "      i += 1\n",
        "      if i >= num_samples:\n",
        "        break\n",
        "\n",
        "    i += padding_needed\n",
        "    # if cube.is_done():\n",
        "    #  print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pdcQeEuiJld9"
      },
      "outputs": [],
      "source": [
        "#Getting Data\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, data):\n",
        "        self.data_list = data\n",
        "\n",
        "    def sample_batch(self, batch_size):\n",
        "        start_indices = np.random.randint(0, len(self.data_list) - 32, size=batch_size)[:, np.newaxis]\n",
        "        indices = start_indices + np.arange(32)[np.newaxis, :]\n",
        "\n",
        "        sample = self.data_list[indices]\n",
        "        return sample\n",
        "\n",
        "data = Dataset(data_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dnqS0mJkMbHd"
      },
      "outputs": [],
      "source": [
        "latent_dim = 32\n",
        "\n",
        "encoder = Encoder(state_dim + action_dim, layer_size=256, latent_dim=latent_dim).to(device)\n",
        "planner = Planner(state_dim, state_dim, layer_size=512, latent_dim=latent_dim).to(device)\n",
        "actor = Actor(state_dim, action_dim, state_dim, layer_size=512, latent_dim=latent_dim).to(device)\n",
        "\n",
        "encoder_optimizer = Adam(encoder.parameters(), lr=1e-4)\n",
        "planner_optimizer = Adam(planner.parameters(), lr=1e-4)\n",
        "actor_optimizer = Adam(actor.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgt8MyeA-ElT"
      },
      "source": [
        "# Training and Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V2A3_IwZB1js"
      },
      "outputs": [],
      "source": [
        "import torch.distributions as dist\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_sample(batch_size, beta, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer, data):\n",
        "    sample = data.sample_batch(batch_size).to(device)\n",
        "    current_state = sample[:, 0, :-18]\n",
        "    current_action = sample[:, 0, -18:]\n",
        "    goal_state = sample[:, -1, :-18]\n",
        "    goal_action = sample[:, -1, -18:]\n",
        "\n",
        "    z, mu_phi, sigma_phi = encoder.forward(sample)\n",
        "    mu_psi, sigma_psi = planner.forward(current_state, goal_state)\n",
        "\n",
        "    phi_gaussian = dist.Normal(mu_phi, sigma_phi)\n",
        "\n",
        "    psi_gaussian = dist.Normal(mu_psi, sigma_psi)\n",
        "\n",
        "    KL_loss = torch.sum(dist.kl.kl_divergence(phi_gaussian, psi_gaussian))\n",
        "\n",
        "    policy_action, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "    action_loss = F.cross_entropy(policy_action.squeeze(1), current_action)\n",
        "\n",
        "    loss = beta * KL_loss + action_loss\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    planner_optimizer.zero_grad()\n",
        "    actor_optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    planner_optimizer.step()\n",
        "    actor_optimizer.step()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRQTwsBKUjee",
        "outputId": "2ac5e728-e083-4e1d-c0ad-1760d0b02f59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch: 0, Loss: 4.640263557434082\n",
            "Batch: 100, Loss: 1.670549988746643\n",
            "Batch: 200, Loss: 1.544872760772705\n",
            "Batch: 300, Loss: 1.230793833732605\n",
            "Batch: 400, Loss: 1.5190844535827637\n",
            "Batch: 500, Loss: 1.3333324193954468\n",
            "Batch: 600, Loss: 1.4156475067138672\n",
            "Batch: 700, Loss: 1.2501029968261719\n",
            "Batch: 800, Loss: 1.1130728721618652\n",
            "Batch: 900, Loss: 1.4968503713607788\n",
            "Batch: 1000, Loss: 1.4110149145126343\n",
            "Batch: 1100, Loss: 1.396974802017212\n",
            "Batch: 1200, Loss: 1.6423795223236084\n",
            "Batch: 1300, Loss: 1.6356810331344604\n",
            "Batch: 1400, Loss: 1.3579951524734497\n",
            "Batch: 1500, Loss: 1.1094772815704346\n",
            "Batch: 1600, Loss: 1.0647872686386108\n",
            "Batch: 1700, Loss: 1.648354411125183\n",
            "Batch: 1800, Loss: 1.4170597791671753\n",
            "Batch: 1900, Loss: 1.1747407913208008\n",
            "Batch: 2000, Loss: 1.1503723859786987\n",
            "Batch: 2100, Loss: 1.8398481607437134\n",
            "Batch: 2200, Loss: 1.1084672212600708\n",
            "Batch: 2300, Loss: 1.3305484056472778\n",
            "Batch: 2400, Loss: 1.2644761800765991\n",
            "Batch: 2500, Loss: 1.2775541543960571\n",
            "Batch: 2600, Loss: 0.9344013333320618\n",
            "Batch: 2700, Loss: 1.4734505414962769\n",
            "Batch: 2800, Loss: 1.4239007234573364\n",
            "Batch: 2900, Loss: 1.1211155652999878\n",
            "Batch: 3000, Loss: 1.677188754081726\n",
            "Batch: 3100, Loss: 1.41400945186615\n",
            "Batch: 3200, Loss: 1.3742542266845703\n",
            "Batch: 3300, Loss: 1.310433268547058\n",
            "Batch: 3400, Loss: 0.8560895919799805\n",
            "Batch: 3500, Loss: 1.537278652191162\n",
            "Batch: 3600, Loss: 1.8765820264816284\n",
            "Batch: 3700, Loss: 1.5951663255691528\n",
            "Batch: 3800, Loss: 1.414899230003357\n",
            "Batch: 3900, Loss: 1.1065417528152466\n",
            "Batch: 4000, Loss: 1.2101541757583618\n",
            "Batch: 4100, Loss: 0.8779466152191162\n",
            "Batch: 4200, Loss: 0.953595757484436\n",
            "Batch: 4300, Loss: 1.6232465505599976\n",
            "Batch: 4400, Loss: 1.5564169883728027\n",
            "Batch: 4500, Loss: 1.4072185754776\n",
            "Batch: 4600, Loss: 1.3102055788040161\n",
            "Batch: 4700, Loss: 1.34438157081604\n",
            "Batch: 4800, Loss: 1.500402569770813\n",
            "Batch: 4900, Loss: 1.338499665260315\n",
            "Batch: 5000, Loss: 1.2280879020690918\n",
            "Batch: 5100, Loss: 1.1136553287506104\n",
            "Batch: 5200, Loss: 1.1579235792160034\n",
            "Batch: 5300, Loss: 1.3509942293167114\n",
            "Batch: 5400, Loss: 1.5205626487731934\n",
            "Batch: 5500, Loss: 0.9818778038024902\n",
            "Batch: 5600, Loss: 1.5256426334381104\n",
            "Batch: 5700, Loss: 1.237512230873108\n",
            "Batch: 5800, Loss: 1.2720962762832642\n",
            "Batch: 5900, Loss: 1.171237587928772\n",
            "Batch: 6000, Loss: 1.4730613231658936\n",
            "Batch: 6100, Loss: 0.9580984711647034\n",
            "Batch: 6200, Loss: 1.5230787992477417\n",
            "Batch: 6300, Loss: 1.0267643928527832\n",
            "Batch: 6400, Loss: 1.0734277963638306\n",
            "Batch: 6500, Loss: 1.157341480255127\n",
            "Batch: 6600, Loss: 1.1756483316421509\n",
            "Batch: 6700, Loss: 0.739629328250885\n",
            "Batch: 6800, Loss: 1.3286452293395996\n",
            "Batch: 6900, Loss: 1.593682885169983\n",
            "Batch: 7000, Loss: 1.4315789937973022\n",
            "Batch: 7100, Loss: 1.1664029359817505\n",
            "Batch: 7200, Loss: 1.2293798923492432\n",
            "Batch: 7300, Loss: 1.2377517223358154\n",
            "Batch: 7400, Loss: 1.5370676517486572\n",
            "Batch: 7500, Loss: 1.1717748641967773\n",
            "Batch: 7600, Loss: 1.6348605155944824\n",
            "Batch: 7700, Loss: 1.0882635116577148\n",
            "Batch: 7800, Loss: 1.282152771949768\n",
            "Batch: 7900, Loss: 1.1797196865081787\n",
            "Batch: 8000, Loss: 1.5700498819351196\n",
            "Batch: 8100, Loss: 1.2630233764648438\n",
            "Batch: 8200, Loss: 1.0237482786178589\n",
            "Batch: 8300, Loss: 1.2605154514312744\n",
            "Batch: 8400, Loss: 1.302283763885498\n",
            "Batch: 8500, Loss: 0.8294535875320435\n",
            "Batch: 8600, Loss: 0.9336796402931213\n",
            "Batch: 8700, Loss: 1.2237482070922852\n",
            "Batch: 8800, Loss: 1.4091582298278809\n",
            "Batch: 8900, Loss: 1.08261239528656\n",
            "Batch: 9000, Loss: 1.2845011949539185\n",
            "Batch: 9100, Loss: 1.377851128578186\n",
            "Batch: 9200, Loss: 1.3096539974212646\n",
            "Batch: 9300, Loss: 0.8136990070343018\n",
            "Batch: 9400, Loss: 1.3677235841751099\n",
            "Batch: 9500, Loss: 1.29616379737854\n",
            "Batch: 9600, Loss: 0.9302650094032288\n",
            "Batch: 9700, Loss: 1.3152750730514526\n",
            "Batch: 9800, Loss: 1.335560917854309\n",
            "Batch: 9900, Loss: 0.8836340308189392\n"
          ]
        }
      ],
      "source": [
        "for batch in range(10000):\n",
        "    loss = train_sample(32, .9, encoder, actor, planner, encoder_optimizer, actor_optimizer, planner_optimizer, data)\n",
        "    if batch % 100 == 0:\n",
        "        print(f\"Batch: {batch}, Loss: {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_XfezATofIWs"
      },
      "outputs": [],
      "source": [
        "def scramble_n(cube, n):\n",
        "    for _ in range(n):\n",
        "        action = random.choice(movements)\n",
        "        cube._rotate_once(action)\n",
        "\n",
        "def attempt_solve(scramble_moves, max_moves):\n",
        "    cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "    goal_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "    scramble_n(cube, scramble_moves)\n",
        "    with torch.no_grad():\n",
        "      current_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "\n",
        "      for t in range(max_moves):\n",
        "        if t % 32 == 0:\n",
        "            mu_psi, sigma_psi = planner.forward(current_state.float(), goal_state.float())\n",
        "        z = mu_psi + sigma_psi * torch.randn_like(sigma_psi)\n",
        "\n",
        "        actor_dist, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "        action_index = torch.argmax(actor_dist, -1)\n",
        "\n",
        "        cube._rotate_once(movements[action_index])\n",
        "        current_state = get_cube_state(cube).flatten().unsqueeze(0).to(device)\n",
        "        if cube.is_done():\n",
        "            return t + 1\n",
        "    return -1\n",
        "\n",
        "\n",
        "def test_batch(batch_size):\n",
        "\n",
        "    cubes = []\n",
        "    histories = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "      history = cube.scramble(1)\n",
        "\n",
        "      cubes.append(cube)\n",
        "      histories.append(history)\n",
        "\n",
        "    return cubes, histories\n",
        "\n",
        "def test_sample(batch_size, encoder, actor, planner):\n",
        "\n",
        "    goal_cube = magiccube.Cube(3,\"YYYYYYYYYRRRRRRRRRGGGGGGGGGOOOOOOOOOBBBBBBBBBWWWWWWWWW\")\n",
        "    goal_state = get_cube_state(goal_cube)\n",
        "    goal_state = goal_state.unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n",
        "    goal_state = goal_state.view(goal_state.size(0), -1)\n",
        "\n",
        "    cubes, histories = test_batch(batch_size)\n",
        "\n",
        "    solved = [False] * batch_size\n",
        "    steps_taken = [0] * batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "      current_state = batch_cube_state(cubes).to(device)\n",
        "\n",
        "      mu_psi, sigma_psi = planner.forward(current_state.float(), goal_state.float())\n",
        "      z = torch.normal(mu_psi, sigma_psi)\n",
        "      actor_dist, _ = actor.forward(current_state.unsqueeze(1), z.unsqueeze(1), goal_state.unsqueeze(1))\n",
        "\n",
        "      best_actions = torch.argmax(actor_dist, -1)\n",
        "\n",
        "      #evaluate\n",
        "      for i, action_index in enumerate(best_actions):\n",
        "        if not solved[i]:\n",
        "          cubes[i]._rotate_once(movements[action_index])\n",
        "          steps_taken[i] += 1\n",
        "          if cubes[i].is_done():\n",
        "            solved[i] = True\n",
        "\n",
        "\n",
        "    num_successful = sum(solved)\n",
        "    print(\"Number of successful solves: \", num_successful)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MinRMH12gTqq",
        "outputId": "2dd64e12-d41e-4432-a0bd-3e48772437b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 :  588\n",
            "2 :  470\n",
            "3 :  315\n",
            "4 :  205\n",
            "5 :  89\n",
            "6 :  77\n",
            "7 :  54\n",
            "8 :  28\n",
            "9 :  20\n",
            "10 :  5\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "for d in range(1, 11):\n",
        "  solve_count = 0\n",
        "  for i in range(1000):\n",
        "    moves = attempt_solve(d, 30)\n",
        "    if moves > 0:\n",
        "      solve_count += 1\n",
        "  print(d, \": \", solve_count)\n",
        "\n",
        "solve_count = 0\n",
        "for i in range(1000):\n",
        "  moves = attempt_solve(30, 80)\n",
        "  if moves > 0:\n",
        "    solve_count += 1\n",
        "print(solve_count)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
